# üöÄ Awesome mmWave Radar Perception [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
  <img src="https://media.tenor.com/ZQIRn2UeT8YAAAAd/dragon-radar.gif" alt="Dragon Radar scanning for Dragon Balls" width="70%" />
</p>

<p align="center">
  <sub>Dragon Radar scanning for breakthroughs in mmWave perception. Animation from Dragon Ball by Akira Toriyama (Bird Studio/Shueisha).</sub>
</p>

**Welcome to the Awesome mmWave Radar Perception repository!**

A curated list of awesome papers, datasets, and resources for millimeter-wave (mmWave) radar perception, with a focus on deep learning methods.

For a broader overview of radar perception beyond mmWave, including research involving modalities such as UWB or LiDAR, please refer to the more comprehensive [awesome-radar-perception](https://github.com/ZHOUYI1023/awesome-radar-perception) repository, which covers a wider spectrum of radar technologies and applications.

Author: Armor

Contact: htkstudy@163.com

Last Updated: **16 November 2025**

## Inclusion Criteria

This list is curated based on the following standards, in order of priority:

- **Reproducibility:** Papers with publicly available code or datasets are the highest priority.
- **Research Focus:** Articles that explore the intersection of deep learning with mmWave radar perception, presenting novel or interesting ideas, are included even without open-source code.
- **Timeliness:** The latest relevant publications from top-tier academic conferences and journals are regularly added to keep the list current.

## Contents

- [üåê Radar Foundational Technologies](#-radar-foundational-technologies)
  - [Signal Processing & Parameter Estimation](#signal-processing--parameter-estimation)
  - [High-Resolution Imaging & SAR Imaging](#high-resolution-imaging--sar-imaging)
  - [Data Synthesis, Enhancement & Simulation](#data-synthesis-enhancement--simulation)
  - [Foundational Models & Representation Learning About Radar Signals](#foundational-models--representation-learning-about-radar-signals)
- [ü§ñ Embodied AI & Robotics](#-embodied-ai--robotics)
- [üöó Autonomous Driving & Drone](#-autonomous-driving--drone)
  - [3D Object Detection & Classification](#3d-object-detection--classification)
  - [Semantic & Instance Segmentation](#semantic--instance-segmentation)
  - [Scene Flow & Motion Prediction](#scene-flow--motion-prediction)
  - [Radar Odometry & Ego-Motion Estimation](#radar-odometry--ego-motion-estimation)
  - [Multi-Object Tracking](#multi-object-tracking)
  - [Simultaneous Localization and Mapping (SLAM)](#simultaneous-localization-and-mapping-slam)
  - [Sensor Fusion Techniques](#sensor-fusion-techniques)
  - [Point Cloud Processing](#point-cloud-processing)
- [ü©∫ Human Sensing & Healthcare](#-human-sensing--healthcare)
  - [Human Activity Recognition (HAR)](#human-activity-recognition-har)
  - [Gesture Recognition & Hand Tracking](#gesture-recognition--hand-tracking)
  - [Occupancy, Presence & Fall Detection](#occupancy-presence--fall-detection)
  - [Pose Estimation & Skeletal Tracking & Human Motion](#pose-estimation--skeletal-tracking--human-motion)
  - [Vital Signs & Biometric Identification](#vital-signs--biometric-identification)
  - [Sleep Monitoring](#sleep-monitoring)
  - [Fatigue driving detection](#fatigue-driving-detection)
  - [Identity Recognition & Person Re-identification](#identity-recognition--person-re-identification)
- [üå± Agriculture Areas](#-agriculture-areas)
- [üè≠ Industrial Areas](#-industrial-areas)
- [üîí Forensics & Privacy Security](#-forensics--privacy-security)
- [üì¶ Other Areas](#-other-areas)
- [ü§ù How to Contribute](#-how-to-contribute)

## üåê Radar Foundational Technologies


### Signal Processing & Parameter Estimation

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [RMD: Robust Modal Decomposition with Constrained Bandwidth](https://arxiv.org/abs/2510.22895) | [Code](https://github.com/Einstein-sworder/RMD) | arXiv | 2025 | Addresses the limitations of existing modal decomposition by mapping the signal into a phase-space trajectory-GRAM matrix to preserve intrinsic structure and incorporating bandwidth constraints to enhance noise resistance. |
| [A Data-centric Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections](https://arxiv.org/abs/2504.13394) | [Code](https://github.com/zzb-nice/DOA_est_Master) | arXiv | 2025 | Addresses DOA estimation accuracy degradation caused by array imperfections through a supervised transfer learning framework that adapts models trained on ideal arrays to real-world conditions. |
| [NEAR: Neural Electromagnetic Array Response](https://proceedings.mlr.press/v267/bu25c.html) | [Code](https://github.com/J1mmyYu1/NEAR) | Proceedings of Machine Learning Research (PMLR) | 2025 | Models electromagnetic array responses as continuous neural fields to improve DOA estimation by capturing complex antenna patterns and mutual coupling effects. |
| [Advancing Single-Snapshot DOA Estimation with Siamese Neural Networks for Sparse Linear Arrays](https://ieeexplore.ieee.org/abstract/document/10890598/) | [Code](https://github.com/ruxinzh/SNNS_SLA) | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2025 | Achieves accurate single-snapshot DOA estimation for sparse linear arrays using Siamese neural networks that learn similarity metrics between spatial patterns. |
| [Advancing High-Resolution and Efficient Automotive Radar Imaging through Domain-Informed 1D Deep Learning](https://ieeexplore.ieee.org/document/10890731) | N/A | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2025 | Enhances automotive radar imaging resolution and computational efficiency by incorporating radar signal processing domain knowledge into 1D convolutional neural networks. |
| [Model-Based Knowledge-Driven Learning Approach for Enhanced High-Resolution Automotive Radar Imaging](https://ieeexplore.ieee.org/abstract/document/10974998) | [Code](https://github.com/ruxinzh/SR-SPECNet) | IEEE Transactions on Radar Systems | 2025 | Combines model-based signal processing with deep unfolding networks to achieve super-resolution radar imaging while maintaining physical interpretability. |
| [Single-Frame MIMO Radar Velocity Vector Estimation via Multi-Bounce Scattering](https://ieeexplore.ieee.org/document/11103510) | N/A | IEEE Transactions on Computational Imaging | 2025 | Estimates full velocity vectors from single-frame MIMO radar data by exploiting multi-bounce scattering paths that provide additional geometric constraints. |
| [Doppler Former: Velocity Supervision of Raw Radar Data](https://ieeexplore.ieee.org/abstract/document/11127345) | [Code](https://github.com/coconut-zs/Fvidar-DopplerFormer) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Introduces a novel Doppler supervision mechanism for raw radar data to enhance velocity estimation accuracy in challenging scenarios. |
| [Direction of Arrival Estimation with Virtual Antenna Array Using FMCW Radar Simulated Data](https://arxiv.org/abs/2508.07513) | [Code](https://github.com/ekurtgl/FMCW-MIMO-Radar-Simulation) | arXiv | 2025 | Addresses the underutilization of velocity information in raw radar data by introducing a plug-and-play 'Doppler Former' module designed to explicitly extract Doppler features and boost perception model performance.|
| [BFAR: improving radar odometry estimation using a bounded false alarm rate detector](https://link.springer.com/article/10.1007/s10514-024-10176-2) | N/A | Autonomous Robots | 2024 | Improves radar odometry accuracy by implementing a bounded false alarm rate detector that filters spurious detections while preserving valid targets. |
| [Antenna Failure Resilience: Deep Learning-Enabled Robust DOA Estimation with Single Snapshot Sparse Arrays](https://ieeexplore.ieee.org/abstract/document/10943029) | [Code](https://github.com/ruxinzh/Deep_RSA_DOA) | 58th Asilomar Conference on Signals, Systems, and Computers | 2024 | Addresses the challenge of single-snapshot DOA estimation in sparse arrays, especially under antenna failure, by proposing a deep learning framework with a novel sparse signal augmentation layer. | 
| [SDOA-Net: An Efficient Deep-Learning-Based DOA Estimation Network for Imperfect Array](https://ieeexplore.ieee.org/abstract/document/10505315) | [Code](https://github.com/chenpengseu/SDOA-Net) | IEEE Transactions on Instrumentation and Measurement | 2024 | Addresses DOA estimation degradation in imperfect arrays by using a deep network that inputs raw signals, rather than covariance matrices, to generate a target-number-agnostic vector for spatial spectrum estimation. |
| [Unfolding Target Detection with State Space Model](https://arxiv.org/abs/2410.22774) | [Code](https://github.com/aiot-lab/NeuroDet) | arXiv | 2024 | Solves the poor performance and difficult tuning of classical CFAR detectors by "unfolding" the algorithm into a state space model, making its parameters learnable while retaining interpretability. |
| [A Two-Stage Multi-Layer Perceptron for High-Resolution DOA Estimation](https://ieeexplore.ieee.org/abstract/document/10443553) | [Code](https://github.com/Whisperzyj/TS-MLP) | IEEE Transactions on Vehicular Technology | 2024 | Solves the poor resolution of existing deep learning DOA methods by using a two-stage MLP that first estimates a coarse grid and then fine-tunes the angle within that grid. |
| [Radar-STDA: A High-Performance Spatial-Temporal Denoising Autoencoder for Interference Mitigation of FMCW Radars](https://arxiv.org/abs/2307.09063) | [Code](https://github.com/GuanRunwei/rd_map_temporal_spatial_denoising_autoencoder) | arXiv | 2023 | Tackles the inefficiency of existing deep learning-based radar interference mitigation by proposing a nano-sized, high-speed spatial-temporal denoising autoencoder that achieves high performance with minimal computational cost. |
| [End-to-End Trainable Deep Neural Network for Radar Interference Detection and Mitigation](https://ieeexplore.ieee.org/document/10371151) | [Code](https://github.com/KIT-MRT/ridam) | IEEE International Radar Conference | 2023 | Proposes an end-to-end deep learning framework that jointly detects and mitigates radar interference, outperforming traditional methods in both accuracy and speed. |
| [Experiments with mmWave Automotive Radar Test-bed](https://ieeexplore.ieee.org/document/9048939) | [Code](https://github.com/Xiangyu-Gao/mmWave-radar-signal-processing-and-microDoppler-classification) | 53rd Asilomar Conference on Signals, Systems, and Computers | 2019 | Details the creation of a lab-scale FMCW radar test-bed using a TI chipset and presents a new, large raw dataset collected with it, validating the platform's utility for ADAS research through preliminary object recognition results. |

### High-Resolution Imaging & SAR Imaging

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [GeRaF: Neural Geometry Reconstruction from Radio Frequency Signals](https://openreview.net/pdf?id=z3PMVmzoya) | N/A | Conference on Neural Information Processing Systems (NeurIPS) | 2025 | Addresses the unique challenges of lens-less, full-space RF signal propagation by introducing a physics-based volumetric rendering pipeline with a novel sampling and blending strategy, making neural 3D reconstruction feasible. |
| [A Single-Frequency Autofocusing Method Based on Conditional Diffusion Model for Millimeter-Wave Near-Range Imaging](https://ieeexplore.ieee.org/document/10966873)| N/A | IEEE Transactions on Geoscience and Remote Sensing | 2025 | Solves the defocusing problem of single-frequency imaging by using an encoder to convert the 3D defocused image into a 2D condition, which then guides a diffusion model to generate a high-quality, focused result. |
| [Millimeter Wave Inverse Pinhole Imaging](https://www.arxiv.org/abs/2510.13904) | N/A | arXiv | 2025 | Enhances the angular resolution of static, compact radars by introducing a rotating physical 'inverse pinhole,' and demonstrates that drone propellers can naturally serve this function for high-resolution imaging while hovering. |
| [Unsupervised 3D SAR Imaging Network Based on Generative Adversary Learning](https://ieeexplore.ieee.org/document/10919030) | [Code](https://github.com/WMMWWM/Unsupervised-3D-SAR-Imaging-Network-Based-on-Generative-Adversary-Learning) | IEEE Transactions on Antennas and Propagation | 2025 | Achieves 3D SAR image reconstruction without paired training data by leveraging generative adversarial networks to learn imaging transformations in an unsupervised manner. |
| [RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes](https://arxiv.org/abs/2505.20967) | [Code](https://github.com/zhan0618/RF4D_code) | arXiv | 2025 | Synthesizes novel radar views of dynamic outdoor scenes by representing 4D radar signals as continuous neural fields that encode spatial and temporal information. |
| [Millimeter-Wave SAR imaging of Sparse Trajectory via Untrained Complex-valued Neural Network](https://arxiv.org/abs/2505.00536) | [Code](https://github.com/Armorhtk/mmUSAR) | IEEE Transactions on Aerospace and Electronic Systems | 2025 | Reconstructs high-quality SAR images from sparse trajectory measurements using untrained complex-valued neural networks that exploit inherent signal structure without requiring pre-training. |
| [Novel Hybrid-Learning Algorithms for Improved Millimeter-Wave Imaging Systems](https://arxiv.org/abs/2306.15341) | [Code](https://github.com/josiahwsmith10/THz-and-Sub-THz-Imaging-Toolbox) | IEEE Journal of Microwaves | 2025 | Proposes a suite of novel hybrid-learning algorithms that interleave signal processing and deep learning to achieve a superior balance of performance and generalizability across diverse mmWave imaging applications. |
| [High-resolution mmWave Imaging using Metasurface and Diffusion](https://dl.acm.org/doi/abs/10.1145/3711875.3729162) | N/A | MobiSys | 2025 | Achieves high-resolution, static mmWave imaging by using an optimized metasurface to encode the scene and a diffusion model to reconstruct the image, replacing mechanical scanning and compressive sensing. |
| [IFNet: Deep Imaging and Focusing for Handheld SAR With Millimeter-Wave Signals](https://ieeexplore.ieee.org/document/10740682) | N/A | IEEE Transactions on Mobile Computing | 2024 | Solves severe handheld motion-induced phase errors in mmWave SAR by proposing a deep unfolding network that embeds signal processing priors into its iterative structure to achieve robust imaging without external trackers. |
| [IFNet: Imaging and Focusing Network for handheld mmWave Devices](https://ieeexplore.ieee.org/document/10447461) | N/A | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2024 | Enables high-quality SAR imaging with handheld mmWave devices by introducing a deep learning framework that compensates for motion-induced phase errors and enhances image focusing. |
| [DART: Implicit Doppler Tomography for Radar Novel View Synthesis](https://arxiv.org/abs/2403.03896) | [Code](https://github.com/WiseLabCMU/dart) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2024 | Proposes a NeRF-inspired method that uses a physics-based (reflectance and transmittance) rendering pipeline to synthesize realistic range-Doppler radar images from novel viewpoints. |
| [Towards large-scale single-shot millimeter-wave imaging for low-cost security inspection](https://www.nature.com/articles/s41467-024-50288-y#code-availability) | [Code](https://github.com/bianlab/MMW) | Nature Communications  | 2024 | Reduces antenna array cost by an order of magnitude by statistically ranking elements to create an optimal sparse layout, and then uses an untrained learning scheme for robust reconstruction from the sparse data. |
| [Fast-Fourier Time-Domain SAR Reconstruction for Millimeter-Wave FMCW 3-D Imaging](https://ieeexplore.ieee.org/document/10549956) | [Code](https://github.com/AdityaMuppala/FMCW-SAR-3D-FFT) | IEEE Transactions on Microwave Theory and Techniques | 2024 | Accelerates 3D FMCW SAR imaging by two orders of magnitude by introducing a fast time-domain reconstruction algorithm (using FFTs/NUFFT) that leverages a novel two-step phase calibration.|
| [FMCW Inverse Circular Synthetic Aperture Radar Using a Fast Time-Domain Reconstruction](https://ieeexplore.ieee.org/abstract/document/10666829) | [Code](https://github.com/AdityaMuppala/FMCW-ICSAR-TDWR/tree/main) | IEEE Transactions on Microwave Theory and Techniques | 2024 | Accelerates inverse circular SAR imaging for real-time applications by adapting frequency-domain wavefront reconstruction into a fast time-domain algorithm and using an analytical PSF to speed up deconvolution.|
| [CoIR: Compressive Implicit Radar](https://ieeexplore.ieee.org/document/10214469) | [Code](https://github.com/sfarrel1/supplement-CoIR) |  IEEE Transactions on Pattern Analysis and Machine Intelligence | 2023 | Achieves data-agnostic, high-resolution sparse radar imaging by leveraging the implicit neural bias of a convolutional decoder as a structural prior, replacing the need for training data or traditional sparsity assumptions. |
| [Quantitative Investigation of Imaging Quality vs. Radar Position Errors in Millimeter-wave SAR](https://ieeexplore.ieee.org/abstract/document/10149744) | [Code](https://github.com/radar-lab/SAR) | IEEE Radar Conference (RadarConf23) | 2023 | Experimentally quantifies how SAR imaging quality at 77 GHz degrades with increasing 2D Gaussian position errors (1mm-256mm) to guide the design of low-cost motion tracking solutions. |
| [Near-distance raw and reconstructed ground based SAR data](https://www.sciencedirect.com/science/article/pii/S2352340923007059) | [Dataset](https://data.mendeley.com/datasets/m458grc688/2) | Data in Brief | 2023 | Addresses material classification from sparse radar data by releasing a dataset (RealSAR) containing raw GBSAR echoes and their corresponding Omega-K reconstructed images. |


### Data Synthesis, Enhancement & Simulation

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian Splatting](https://arxiv.org/abs/2505.20714) | [Code](https://github.com/sim-2-real/Wideband3DGS) | arXiv | 2025 | Models wideband RF propagation in 3D scenes by embedding frequency information into Gaussian splatting representations for accurate multi-frequency signal prediction. |
| [Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts](https://arxiv.org/abs/2504.14621) | [Code](https://github.com/zk-b612/WiTalk) | arXiv | 2025 | Enhances wireless sensing model performance by leveraging text prompts and large language models to provide semantic guidance for radar data interpretation. |
| [One Snapshot is All You Need: A Generalized Method for mmWave Signal Generation](https://ieeexplore.ieee.org/abstract/document/10416806) | N/A | IEEE INFOCOM | 2025 | Generates diverse mmWave signals from a single snapshot by learning generalizable representations that capture signal patterns across different scenarios. |
| [Synthetic Radar Signal Generator for Human Motion Analysis](https://ieeexplore.ieee.org/abstract/document/10804837) | N/A | IEEE Transactions on Radar Systems | 2025 | Synthesizes realistic radar signals for human motion scenarios by integrating motion-capture data with radar signal models to overcome data scarcity. |
| [Diffusion^2: Turning 3D Environments into Radio Frequency Heatmaps](https://arxiv.org/abs/2510.02274) | [Project](https://rfvision-project.github.io/) | arXiv | 2025 | Predicts RF signal propagation patterns in 3D environments using cascaded diffusion models that generate spatially-aware channel heatmaps. |
| [Inverse Rendering of Near-Field mmWave MIMO Radar for Material Reconstruction](https://ieeexplore.ieee.org/document/10892639/) | [Code](https://github.com/nihofm/inverse-radar-rendering) | IEEE Journal of Microwaves | 2025 | Reconstructs material properties of objects from near-field radar measurements by formulating an inverse rendering problem that recovers dielectric characteristics. |
| [Simulate Any Radar: Attribute-Controllable Radar Simulation via Waveform Parameter Embedding](https://arxiv.org/abs/2506.03134) | [Code](https://github.com/zhuxing0/SA-Radar) | arXiv | 2025 | Enables controllable radar simulation across different configurations by embedding waveform parameters into generative models for flexible data augmentation. |
| [L2RDaS: Synthesizing 4D Radar Tensors for Model Generalization via Dataset Expansion](https://arxiv.org/abs/2503.03637) | [Project](https://github.com/kaist-avelab/K-Radar) | arXiv | 2025 | Improves model generalization by synthesizing realistic 4D radar tensors through learning-to-learn approaches that expand training dataset diversity. |
| [MITO: A Millimeter-Wave Dataset and Simulator for Non-Line-of-Sight Perception](https://arxiv.org/abs/2502.10259) | [Code](https://github.com/signalkinetics/MITO_Codebase/tree/main) | arXiv | 2025 | Provides a comprehensive dataset and physics-based simulator for NLOS radar perception enabling research on seeing around corners with synthetic aperture techniques. |
| [RadaRays: Real-time Simulation of Rotating FMCW Radar for Mobile Robotics via Hardware-accelerated Ray Tracing](https://ieeexplore.ieee.org/abstract/document/10845807) | [Code](https://github.com/uos/radarays) | IEEE Robotics and Automation Letters | 2025 | Develops a real-time radar simulator that uses hardware-accelerated ray tracing to more accurately model complex wave phenomena like reflection and scattering, overcoming the limitations of simplistic, lidar-like simulations in existing platforms.|
| [RF-Diffusion: Radio Signal Generation via Time-Frequency Diffusion](https://dl.acm.org/doi/10.1145/3636534.3649348) | [Code](https://github.com/yourusername/RF-Diffusion) | MobiCom | 2024 | Generates realistic radio signals by applying diffusion models in the time-frequency domain to capture complex signal characteristics and variations. |
| [Generative Artificial Intelligence Meets Synthetic Aperture Radar: A survey](https://ieeexplore.ieee.org/abstract/document/10752552) | [Code](https://github.com/XAI4SAR/GenAIxSAR) | IEEE Geoscience and Remote Sensing Magazine | 2024 | Surveys the intersection of generative AI techniques with SAR imaging, highlighting advancements in data synthesis, super-resolution, and anomaly detection. |
| [RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar Object Detection With Simulation](https://openaccess.thecvf.com/content/CVPR2024/html/Bialer_RadSimReal_Bridging_the_Gap_Between_Synthetic_and_Real_Data_in_CVPR_2024_paper.html) | [Code](https://yuvalhg.github.io/RadSimReal/)  | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2024 | Solves the radar data annotation challenge by proposing a fast physical simulator that bypasses the need for proprietary radar design details and produces synthetic data capable of matching or exceeding real-data training performance.|
| [Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks](https://arxiv.org/abs/2308.02632) | [Code](https://github.com/eduardo-candioto-fidelis/raw-radar-data-generation) | arXiv | 2023 | Addresses the speed and noise-modeling limitations of ray tracing by using a Generative Adversarial Network (GAN) to generate realistic, raw radar sensor data for data augmentation in critical scenarios.|
| [An Open Framework to Model Diffraction by Dynamic Blockers in Millimeter Wave Simulations](https://ieeexplore.ieee.org/document/9810361) | [Code](https://github.com/signetlabdei/rt-blockage-manager) |Mediterranean Communication and Computer Networking Conference (MedComNet)| 2022| Addresses the challenge of simulating multiple, dynamic blockers in mmWave channels by releasing an open-source framework that models diffraction and interfaces with existing ray-tracing software. |


### Foundational Models & Representation Learning About Radar Signals

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer](https://arxiv.org/abs/2507.21799) | [Code](https://github.com/rfcrate/RF_CRATE) | arXiv | 2025 | Develops an interpretable transformer architecture for RF sensing that processes complex-valued signals while maintaining transparency in feature learning and decision-making. |
| [Multi-View Radar Detection Transformer with Differentiable Positional Encoding](https://ieeexplore.ieee.org/document/10889849/) | N/A | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2025 | Enhances multi-view radar detection by introducing differentiable positional encodings that adapt to radar geometry and improve cross-view feature aggregation. |
| [Towards Foundational Models for Single-Chip Radar](https://arxiv.org/abs/2509.12482) | [Project](https://wiselabcmu.github.io/grt/) | arXiv | 2025 | Builds foundation models for single-chip radar through self-supervised pre-training on diverse radar data to enable transfer learning across multiple sensing tasks. |
| [SpikingRTNH: Spiking Neural Network for 4D Radar Object Detection](https://arxiv.org/abs/2502.00074) | [Code](https://github.com/kaist-avelab/K-Radar/tree/main/models/skeletons) | arXiv | 2025 | Achieves energy-efficient 4D radar object detection using spiking neural networks that exploit temporal sparsity in radar signals for low-power processing. |
| [Talk2Radar: Bridging Natural Language with 4D mmWave Radar for 3D Referring Expression Comprehension](https://arxiv.org/abs/2405.12821) | [Code](https://github.com/GuanRunwei/Talk2Radar) | arXiv | 2024 | Establishes a new research direction by creating the first-ever dataset and a baseline model that connects natural language expressions to objects within 4D mmWave radar point clouds for 3D referring expression comprehension.|
| [FMCW Radar Sensing for Indoor Drones Using Learned Representations](https://arxiv.org/abs/2301.02451) | [Dataset](https://thesmartrobot.github.io/datasets) | arXiv | 2023 | Addresses the inefficiency of task-specific deep learning for radar by using unsupervised learning to generate reusable, low-dimensional representations from raw FMCW data for various downstream tasks. |

## ü§ñ Embodied AI & Robotics

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation](https://arxiv.org/abs/2511.01210v2) | N/A | arXiv | 2025 | Solves the challenge of fusing diverse non-visual sensors (IR, radar, audio) into RGB-pretrained VLA models by creating a "sensor-masked image," a unified representation that overlays physical sensor data onto the RGB image. |
| [Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks](https://arxiv.org/abs/2502.13175) | N/A | arXiv | 2025 | Comprehensively surveys security vulnerabilities in embodied AI systems including sensor spoofing and adversarial attacks on perception and decision-making modules. |
| [FuseGrasp: Radar-Camera Fusion for Robotic Grasping of Transparent Objects](https://ieeexplore.ieee.org/document/10909339) | N/A | IEEE Transactions on Mobile Computing | 2025 | Enables robust grasping of transparent objects by fusing radar material sensing with camera visual information to overcome camera limitations on reflective surfaces. |
| [Non-Line-of-Sight 3D Object Reconstruction via mmWave Surface Normal Estimation](https://dl.acm.org/doi/10.1145/3711875.3729138) | [Code](https://github.com/signalkinetics/mmNorm) | MobiSys | 2025 | Reconstructs hidden 3D objects by estimating surface normals from mmWave multipath reflections using synthetic aperture radar imaging principles. |
| [Loosely coupled 4D-Radar-Inertial Odometry for Ground Robots](https://arxiv.org/abs/2411.17289) | [Code](https://github.com/robotics-upo/4D-Radar-Odom) | arXiv | 2025 | Achieves robust ground robot odometry in challenging conditions through loosely-coupled fusion of 4D radar measurements with inertial sensor data. |


## üöó Autonomous Driving & Drone


### 3D Object Detection & Classification

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [SSMRadNet : A Sample-wise State-Space Framework for Efficient and Ultra-Light Radar Segmentation and Object Detection](https://arxiv.org/abs/2511.08769) | N/A | arXiv | 2025 | Proposes the first State Space Model (SSM) for raw radar data that sequentially processes samples at both the chirp and frame level, drastically reducing computational cost and model size compared to CNN/Transformer methods. |
| [Pillar-Based Adaptive Sparse Transformer with Cost-Optimized Positive Sample Selection for 4D Radar Object Detection](https://link.springer.com/article/10.1007/s13177-025-00569-7) | N/A | International Journal of Intelligent Transportation Systems Research | 2025| Solves the limited receptive field of 3D convnets by using a sparse pillar transformer (for long-range context) and addresses poor label assignment by using a novel cross-label head to ensure balanced positive samples. |
| [M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar](https://arxiv.org/abs/2510.27166) | N/A | arXiv | 2025 | Solves the problem of incomplete single-frame data by proposing a multi-frame fusion framework that efficiently aggregates features at both the global-object level (guided by radar) and local-grid level (guided by trajectories). |
| [SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion](https://arxiv.org/abs/2510.19215) | N/A | arXiv | 2025 |Overcomes radar sparsity by using a quadratic surface fitting model to generate dense depth, which in turn guides the image-to-BEV transformation and creates dense pseudo-points. |
| [DA3D: Domain-Aware Dynamic Adaptation for All-Weather Multimodal 3D Detection](https://dl.acm.org/doi/abs/10.1145/3746027.3755708) | [Code](https://github.com/Dawns14/DA3D) | ACM International Conference on Multimedia | 2025 | Addresses feature-level domain shifts in multi-sensor fusion by using LoRA as a dynamic "capacity controller" to efficiently reallocate model parameters based on weather difficulty. |
| [Doppler-Aware LiDAR-RADAR Fusion for Weather-Robust 3D Detection](https://openaccess.thecvf.com/content/ICCV2025/papers/Chae_Doppler-Aware_LiDAR-RADAR_Fusion_for_Weather-Robust_3D_Detection_ICCV_2025_paper.pdf) | [Code](https://github.com/yujeong-star/DLRFusion) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Solves the problem of poor Doppler encoding in existing fusion methods by introducing a multi-path iterative module that uses Doppler to highlight dynamic regions, which in turn progressively refines both RADAR power and LiDAR features. |
| [RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection](https://openaccess.thecvf.com/content/CVPR2025/html/Long_RICCARDO_Radar_Hit_Prediction_and_Convolution_for_Camera-Radar_3D_Object_CVPR_2025_paper.html) | [Code](https://github.com/longyunf/riccardo) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2025 | Enhances camera-radar fusion by predicting where radar hits should occur on objects and performing convolutions in predicted hit space for improved 3D detection. |
| [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330) | [Project](https://yuvalhg.github.io/DoppDrive/) | arXiv | 2025 | Improves radar object detection by using Doppler velocity measurements to guide temporal aggregation of radar frames for motion-aware feature learning. |
| [RadarNeXt: Real-Time and Reliable 3D Object Detector Based On 4D mmWave Imaging Radar](https://arxiv.org/abs/2501.02314) | [Code](https://github.com/Pay246-git468/RadarNeXt) | arXiv | 2025 | Achieves real-time 3D object detection from 4D radar by designing efficient architectures that balance accuracy and computational efficiency for automotive deployment. |
| [RADLER: Radar Object Detection Leveraging Semantic 3D City Models and Self-Supervised Learning](https://openaccess.thecvf.com/content/CVPR2025W/PBVS/html/Luo_RADLER_Radar_Object_Detection_Leveraging_Semantic_3D_City_Models_and_CVPRW_2025_paper.html) | [Project](https://gpp-communication.github.io/RADLER/) | CVRP | 2025 | Improves radar object detection by leveraging semantic 3D city models as prior knowledge and using self-supervised learning to reduce annotation requirements. |
| [Beyond Pillars: Advancing 3D Object Detection with Salient Voxel Enhancement of LiDAR-4D Radar Fusion](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5518546) | [Code](https://github.com/icdm-adteam/SVEFusion) | SSRN | 2025 | Advances beyond pillar-based representations by identifying and enhancing salient voxels in LiDAR-radar fusion for more discriminative 3D object features. |
| [RCDFNet: A 4-D Radar and Camera Dual-Level Fusion Network for 3-D Object Detection](https://ieeexplore.ieee.org/abstract/document/11006930) | [Code](https://github.com/D-Hourse/RCDFNet/tree/master) | IEEE Sensors Journal | 2025 | Performs radar-camera fusion at both feature and decision levels to complement strengths of each modality for robust 3D object detection across conditions. |
| [V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion](https://arxiv.org/abs/2411.08402) | [Code](https://github.com/ylwhxht/V2X-R) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2025 | Enables cooperative perception in V2X scenarios by fusing LiDAR and 4D radar across vehicles using denoising diffusion to handle communication noise. |
| [RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features](https://arxiv.org/abs/2508.15353) | [Code](https://github.com/OlgaMatykina/RCDINO) | arXiv | 2025 | Enhances radar-camera 3D detection by incorporating DINOv2's rich semantic features to provide better object understanding and context awareness. |
| [CenterRadarNet: Joint 3D Object Detection and Tracking Framework Using 4D FMCW Radar](https://ieeexplore.ieee.org/abstract/document/10648077) | [Code](https://github.com/Andy-Cheng/CenterRadarNet) | IEEE International Conference on Image Processing (ICIP) | 2024 | Overcomes the limitations of 3D radar tensors by using 4D (elevation) radar data in a joint architecture that simultaneously learns representations for both 3D object detection and re-identification. |
| [E-RODNet: Lightweight Approach to Object Detection by Vehicular Millimeter-Wave Radar](https://ieeexplore.ieee.org/abstract/document/10666091) | [Code](https://github.com/lupeng-xm/E-RODNet) | IEEE Sensors Journal  | 2024 | Addresses the excessive complexity of current radar perception models by proposing a lightweight ConvFormer-based architecture that integrates a global feature fusion module to achieve SOTA performance with minimal computational cost. |
| [Bootstrapping Autonomous Driving Radars with Self-Supervised Learning](https://openaccess.thecvf.com/content/CVPR2024/html/Hao_Bootstrapping_Autonomous_Driving_Radars_with_Self-Supervised_Learning_CVPR_2024_paper.html) | [Code](https://github.com/yiduohao/Radical) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2024 | Solves the radar annotation bottleneck by using a self-supervised framework with combined radar-to-radar and radar-to-vision contrastive losses to pre-train models on unlabeled data.|
| [LEROjD: Lidar Extended Radar-Only Object Detection](https://link.springer.com/content/pdf/10.1007/978-3-031-73027-6_22.pdf) | [Code](https://github.com/rst-tu-dortmund/lerojd) | ECVA | 2024 | Improves radar-only object detection by proposing two training strategies (multi-stage LiDAR thin-out and knowledge distillation) that transfer knowledge from LiDAR data without requiring architecture changes. |
| [DPFT: Dual Perspective Fusion Transformer for Camera-Radar-based Object Detection](https://ieeexplore.ieee.org/abstract/document/10769556) | [Code](https://github.com/TUMFTM/DPFT) | IEEE Transactions on Intelligent Vehicles  | 2024 | Solves the radar sparsity problem by using the raw radar cube instead of point clouds, and effectively leverages elevation information by fusing features in both camera and ground-plane perspectives. |
| [RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection Systems](https://ieeexplore.ieee.org/abstract/document/10812016) | [Code](https://github.com/yyxr75/RaLiBEV) | IEEE Transactions on Circuits and Systems for Video Technology | 2024 | Addresses the weak feature interaction and inconsistent regression of existing LiDAR-radar fusion methods by introducing an interactive transformer module and an advanced label assignment strategy. |
| [Robust 3D Object Detection from LiDAR-Radar Point Clouds Via Cross-Modal Feature Augmentation](https://ieeexplore.ieee.org/abstract/document/10610775) | [Code](https://github.com/DJNing/See_beyond_seeing) |  IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Improves the performance of single-modal 3D detectors (LiDAR-only or radar-only) by training them with a cross-modal "hallucination" framework that uses spatial and feature alignment to refine each sensor's backbone with knowledge from the other.|
| [Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection](https://ieeexplore.ieee.org/abstract/document/10186820) | [Code](https://github.com/kaist-avelab/K-Radar) | IEEE Intelligent Vehicles Symposium (IV) | 2023 | Addresses the high memory cost of 4D radar tensors by empirically determining an optimal density reduction level (5%) and introducing an offline sparse representation (4DSRT) to accelerate training.|
| [Utilizing Super-Resolution for Enhanced Automotive Radar Object Detection](https://ieeexplore.ieee.org/abstract/document/10222681) | [Code](https://github.com/kanishkaisreal/DLSR_CRUW) | IEEE International Conference on Image Processing (ICIP) | 2023 | Addresses the lack of paired high/low-resolution radar data by first training a super-resolution model on simulated data, and then using this model to enhance a real-world dataset for object detection. |
| [Radar Range‚ÄìDoppler Flow: A Radar Signal Processing Technique to Enhance Radar Target Classification](https://ieeexplore.ieee.org/abstract/document/10336382) | [Code](https://github.com/radar-lab/RD_Flow) | IEEE Transactions on Aerospace and Electronic Systems | 2023 | Solves the failure of traditional radar clustering (when targets are close and at similar speeds) by introducing radial acceleration, extracted via "range‚ÄìDoppler flow," as an additional distinguishing feature. |

### Semantic & Instance Segmentation

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [RC-ROSNet: Fusing 3D Radar Range-Angle Heat Maps and Camera Images for Radar Object Segmentation](https://ieeexplore.ieee.org/document/11112643) | [Code](https://github.com/Zhuanglong2/RC-ROSNet) | IEEE Transactions on Circuits and Systems for Video Technology | 2025 | Performs radar object segmentation by fusing 3D range-angle heatmaps with camera images to leverage complementary spatial and semantic information. |
| [M2CNet: LiDAR 3D Semantic Segmentation Based on Multi-level Multi-view Cross-attention Fusion for Autonomous Vehicles](https://ieeexplore.ieee.org/document/11125962/) | [Code](https://github.com/Terminal-lidar/M2CNet) | IEEE Transactions on Vehicular Technology | 2025 | Enhances LiDAR semantic segmentation through multi-level multi-view cross-attention that captures both local details and global context for autonomous driving. |
| [RadarMask: A Novel End-to-End Sparse Millimeter-Wave Radar Sequence Panoptic Segmentation and Tracking Method](https://ieeexplore.ieee.org/abstract/document/11128555) | [Code](https://github.com/yb-guo/RadarMask) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Performs end-to-end panoptic segmentation and tracking on sparse mmWave radar sequences by jointly learning instance masks and temporal associations. |
| [RETR: Multi-View Radar Detection Transformer for Indoor Perception](https://neurips.cc/virtual/2024/poster/95530) | [Code](https://github.com/merlresearch/radar-detection-transformer) | Conference on Neural Information Processing Systems (NeurIPS) | 2024 | Achieves robust indoor perception by aggregating multi-view radar data through transformer architecture that handles varying spatial perspectives and occlusions. |
| [4D Radar And Vision Fusion Detection Model Based On Segmentation-assisted](https://www.researchsquare.com/article/rs-5358941/v1) | [Code](https://github.com/Huniki/RVASANET) | arXiv | 2024 | Improves 4D radar-vision fusion detection by using segmentation results as intermediate supervision to guide feature learning and alignment between modalities. |
| [AdaPKC: PeakConv with Adaptive Peak Receptive Field for Radar Semantic Segmentation](https://proceedings.neurips.cc/paper_files/paper/2024/hash/f6b22ac37beb5da61efd4882082c9ecd-Abstract-Conference.html) | [Code](https://github.com/lihua199710/AdaPKC) | Conference on Neural Information Processing Systems (NeurIPS) | 2024 | Addresses radar sparsity in semantic segmentation through adaptive peak convolutions that dynamically adjust receptive fields based on local point density. |
| [TARSS-Net: Temporal-Aware Radar Semantic Segmentation Network](https://neurips.cc/virtual/2024/poster/96608) | [Code](https://github.com/zlw9161/TARSS-NeT) | Conference on Neural Information Processing Systems (NeurIPS) | 2024 | Enhances radar semantic segmentation by explicitly modeling temporal dependencies across consecutive frames to leverage motion information for better predictions. |
| [Achelous++: Power-Oriented Water-Surface Panoptic Perception Framework on Edge Devices based on Vision-Radar Fusion and Pruning of Heterogeneous Modalities](https://arxiv.org/abs/2312.08851) | [Code](https://github.com/GuanRunwei/Achelous) | arXiv | 2024 | Addresses the high power consumption of water-surface perception models by proposing a lightweight, vision-radar fusion framework with a novel multi-modal pruning strategy to enable efficient multi-task learning on edge devices. |
| [ASY-VRNet: Waterway Panoptic Driving Perception Model based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar](https://ieeexplore.ieee.org/document/10802447) | [Code](https://github.com/GuanRunwei/ASY-VRNet) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Addresses the differing feature requirements of object detection and semantic segmentation by proposing an asymmetric fusion module that treats both vision and radar as point sets to create a task-specific shared feature space.|
| [RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale](https://ieeexplore.ieee.org/abstract/document/10610929) | [Code](https://github.com/MMOCKING/RadarCam-Depth) | IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Addresses the artifacts of direct camera-radar data fusion by proposing a four-stage pipeline that uses sparse radar to learn a dense, refined metric scale map, which is then applied to correct a monocular depth prediction. |
| [The ADUULM-360 Dataset - A Multi-Modal Dataset for Depth Estimation in Adverse Weather](https://ieeexplore.ieee.org/abstract/document/10920201) | [Dataset](https://github.com/uulm-mrm/aduulm_360_dataset) | IEEE 27th International Conference on Intelligent Transportation Systems (ITSC) | 2024 | Addresses the lack of adverse weather scenes in depth estimation datasets by releasing a comprehensive 360-degree, multi-modal (camera, LiDAR, radar) dataset to benchmark and expose the limitations of current methods in such conditions. |
| [Cross-Modal Supervision Based Road Segmentation and Trajectory Prediction With Automotive Radar](https://ieeexplore.ieee.org/abstract/document/10628992) | [Code](https://wangzhaoze.github.io/RADxGPS/) | IRAL | 2024 | Solves the radar annotation bottleneck by using DGPS as a cross-modal supervisor to automatically generate labels for training a multi-task network for road segmentation and trajectory prediction. |
| [RIDERS: Radar-Infrared Depth Estimation for Robust Sensing](https://ieeexplore.ieee.org/abstract/document/10623522) | [Code](https://github.com/MMOCKING/RIDERS) | IEEE Transactions on Intelligent Transportation Systems | 2024 | Solves the challenge of depth estimation in adverse weather by fusing a monocular infrared camera with radar, using the sparse radar data to learn a dense scale map that corrects the infrared-based depth prediction. |
| [TransRadar: Adaptive-Directional Transformer for Real-Time Multi-View Radar Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Dalbah_TransRadar_Adaptive-Directional_Transformer_for_Real-Time_Multi-View_Radar_Semantic_Segmentation_WACV_2024_paper.html) | [Code](https://github.com/YahiDar/TransRadar) | Winter Conference on Applications of Computer Vision (WACV) | 2024 | Addresses the challenges of radar sparsity and noise in semantic segmentation by introducing an adaptive-directional transformer that captures long-range dependencies while focusing on relevant spatial regions. |
| [PeakConv: Learning Peak Receptive Field for Radar Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_PeakConv_Learning_Peak_Receptive_Field_for_Radar_Semantic_Segmentation_CVPR_2023_paper.html) | [Code](https://github.com/zlw9161/PKC) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2023 | Addresses the mismatch of standard convolutions with radar signals by introducing a "Peak Convolution" (PeakConv) inspired by the classic CFAR principle of detecting local peak responses. |
| [Multi-View Radar Semantic Segmentation](https://arxiv.org/abs/2103.16214) | [Code](https://github.com/valeoai/MVRSS) | IEEE International Conference on Computer Vision (ICCV) | 2021 | Proposes lightweight architectures that analyze multiple 2D "views" (projections) of the raw range-angle-Doppler tensor to achieve efficient and accurate radar semantic segmentation. |

### Scene Flow & Motion Prediction

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Self-Supervised Diffusion-Based Scene Flow Estimation and Motion Segmentation with 4D Radar](https://ieeexplore.ieee.org/document/10974572) | [Code](https://github.com/nubot-nudt/RadarSFEMOS) | IRAL | 2025 | Estimates scene flow and segments moving objects from 4D radar using self-supervised diffusion models that learn motion patterns without manual annotations. |
| [DoGFlow: Self-Supervised LiDAR Scene Flow via Cross-Modal Doppler Guidance](https://arxiv.org/abs/2505.06056) | [Project](https://ajinkyakhoche.github.io/DogFlow/) | arXiv | 2025 | Overcomes the bottleneck of manual annotation for LiDAR scene flow by using a self-supervised method that generates pseudo-labels from radar Doppler measurements, significantly improving performance and data efficiency. |
| [milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing](https://link.springer.com/chapter/10.1007/978-3-031-72691-0_12) | [Code](https://github.com/Toytiny/milliFlow) | European Conference on Computer Vision (ECCV) | 2024 | Uses deep learning to estimate scene flow from mmWave point clouds, creating a new intermediate motion representation that boosts performance on downstream tasks like human activity recognition and parsing. |
| [HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors](https://ieeexplore.ieee.org/abstract/document/10801938) | [Dataset](https://github.com/minwoo0611/HeLiPR-Pointcloud-Toolbox) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Addresses the lack of MOS datasets for diverse (e.g., solid-state) LiDARs by releasing a new heterogeneous dataset (HeLiMOS) generated using a novel automatic labeling pipeline. |

### Radar Odometry & Ego-Motion Estimation

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [S3E: Self-Supervised State Estimation for Radar-Inertial System](https://openaccess.thecvf.com/content/ICCV2025/html/Wang_S3E_Self-Supervised_State_Estimation_for_Radar-Inertial_System_ICCV_2025_paper.html) | [Code](https://github.com/wsp666/S3E) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Bypasses sparse point clouds by using richer radar spectra and fuses inertial data in a self-supervised manner, employing a novel cross-fusion technique to overcome poor angular resolution. |
| [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://ieeexplore.ieee.org/abstract/document/11128046) | [Code](https://github.com/NeSC-IV/AF-RLIO) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Improves multi-sensor odometry by using radar to not only provide complementary data but also to actively de-noise LiDAR and determine its reliability, enabling an adaptive fusion for robust navigation in degraded conditions. |
| [RINO: Accurate, Robust Radar-Inertial Odometry With Non-Iterative Estimation](https://ieeexplore.ieee.org/abstract/document/11134416) | [Code](https://github.com/yangsc4063/rino) | IEEE Transactions on Automation Science and Engineering  | 2025 | Achieves accurate radar-inertial odometry by introducing a non-iterative estimation framework that reduces computational complexity while maintaining robustness against radar noise and outliers. |
| [Digital Beamforming Enhanced Radar Odometry](https://ieeexplore.ieee.org/document/11127292) | [Code](https://github.com/SenseRoboticsLab/DBE-Radar) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Improves radar odometry accuracy by applying digital beamforming to enhance angular resolution and reduce multipath interference for better feature matching. |
| [DRO: Doppler-Aware Direct Radar Odometry](https://arxiv.org/abs/2504.20339) | [Code](https://github.com/utiasASRL/dro) | RSS | 2025 | Achieves accurate direct radar odometry by explicitly incorporating Doppler velocity measurements into optimization framework to constrain ego-motion estimation. |
| [GaRLIO: Gravity enhanced Radar-LiDAR-Inertial Odometry](https://arxiv.org/abs/2502.07703) | [Code](https://github.com/ChiyunNoh/GaRLIO) | arXiv | 2025 | Enhances multi-sensor odometry by incorporating gravity direction as additional constraint to improve radar-LiDAR-inertial fusion accuracy and robustness. |
| [Ground-Optimized 4D Radar-Inertial Odometry via Continuous Velocity Integration using Gaussian Process](https://arxiv.org/abs/2502.08093) | [Code](https://github.com/wooseongY/Go-RIO) | arXiv | 2025 | Optimizes radar-inertial odometry for ground vehicles by using Gaussian processes to model continuous velocity integration and handle ground constraint. |
| [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)| N/A | arXiv | 2025 | Achieves robust radar odometry by leveraging equivariant neural networks that respect geometric transformations and improve generalization across diverse motion patterns. |
| [Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry](https://arxiv.org/abs/2506.18580) | [Code](https://github.com/aau-cns/radar_transformer) | arXiv | 2025 | Improves radar-inertial odometry by using a self-supervised Transformer network to find robust point correspondences, uniquely generating training data by solving a linear sum assignment problem to avoid manual labeling. |
| [Radar4VoxMap: Accurate Odometry from Blurred Radar Observations](https://ieeexplore.ieee.org/abstract/document/11128118) | [Code](https://github.com/ailab-hanyang/Radar4VoxMap) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Tackles the issue of submap blurring from cumulative errors in radar odometry by using an RCS-weighted voxel map and a fixed-lag graph optimization that jointly refines both the map and the vehicle's pose. |
| [EFEAR-4DÔºöEgo-velocity Filtering for Efficient and Accurate 4D radar Odometry](https://ieeexplore.ieee.org/document/10685149) | [Code](https://github.com/CLASS-Lab/EFEAR-4D) | IEEE Robotics and Automation Letters | 2024 | Improves 4D radar odometry efficiency by filtering radar points based on ego-velocity consistency to remove dynamic objects and outliers. |
| [RadarMOSEVE: A Spatial-Temporal Transformer Network for Radar-Only Moving Object Segmentation and Ego-Velocity Estimation](https://ojs.aaai.org/index.php/AAAI/article/view/28240) | [Code](https://github.com/ORCA-Uboat/RadarMOSEVE) | AAAI Conference on Artificial Intelligence (AAAI) | 2024 | Proposes a Transformer network with custom self- and cross-attention mechanisms designed to leverage radar's radial velocity information to overcome data sparsity and noise for simultaneous moving object segmentation and ego-velocity estimation. |
| [DeRO: Dead Reckoning Based on Radar Odometry With Accelerometers Aided for Robot Localization](https://ieeexplore.ieee.org/document/10801645) | [Code](https://github.com/hoangvietdo/dero) |IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Mitigates localization drift by using radar Doppler velocity and gyroscope data for direct dead reckoning, while using accelerometer-derived tilt angles and scan matching for Kalman filter updates, thus avoiding error-prone accelerometer double integration.|
| [Continuous-Time Radar-Inertial and Lidar-Inertial Odometry Using a Gaussian Process Motion Prior](https://ieeexplore.ieee.org/abstract/document/10816238) | [Code](https://github.com/utiasASRL/steam_icp) | IEEE Transactions on Robotics | 2024 | Enables continuous-time radar-inertial odometry for a spinning radar by using a Gaussian process motion prior and IMU preintegration within a sliding-window batch estimator. |
| [A Robust Baro-Radar-Inertial Odometry M-Estimator for Multicopter Navigation in Cities and Forests](https://ieeexplore.ieee.org/document/10705761) | [Dataset](https://www.research-collection.ethz.ch/entities/researchdata/99624de7-3f89-4411-9894-c8ff8ba0f009) | IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI) | 2024 | Enhances multicopter navigation in challenging environments by fusing barometer, radar, and inertial data using an M-estimator framework that robustly handles outliers and sensor noise. |
| [Successive Pose Estimation and Beam Tracking for mmWave Vehicular Communication Systems](https://ieeexplore.ieee.org/document/10464790) | [Code](https://github.com/Cen-Liu/Fast-CFEAR-Radar-Odometry) | IEEE Transactions on Vehicular Technology | 2024 | Alleviates beam training overhead in vehicular mmWave communications by first estimating the vehicle's pose via radar odometry and then using this information within an Extended Kalman Filter to proactively track the communication beam. |
| [Open-RadVLAD: Fast and Robust Radar Place Recognition](https://ieeexplore.ieee.org/abstract/document/10548974) | [Code](https://github.com/mttgdd/open-radvlad) |IEEE Radar Conference | 2024 | Achieves robust and efficient radar place recognition by applying a 1D Fourier Transform along radial power returns for partial translational invariance and a VLAD descriptor for rotational invariance. |
| [Degradation Resilient LiDAR-Radar-Inertial Odometry](https://ieeexplore.ieee.org/abstract/document/10611444) | [Code](https://github.com/ntnu-arl/lidar_degeneracy_datasets) | IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Mitigates LiDAR odometry failure by using a tightly-coupled factor graph that allows LiDAR to contribute partial information along its reliable axes, while radar and inertial data provide complementary support. |
| [OORD: The Oxford Offroad Radar Dataset](https://ieeexplore.ieee.org/abstract/document/10648882) | [Dataset](https://oxford-robotics-institute.github.io/oord-dataset/) | IEEE Transactions on Intelligent Transportation Systems | 2024 | Fills the gap of urban-centric data by releasing a large-scale radar dataset (OORD) collected in rugged, extreme-weather offroad environments to benchmark place recognition. |
| [Co-RaL: Complementary Radar-Leg Odometry with 4-DoF Optimization and Rolling Contact](https://ieeexplore.ieee.org/abstract/document/10801960) | [Code](https://github.com/SangwooJung98/Co-RaL-Dataset) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Improves legged robot localization by tightly coupling radar and leg odometry, using 4-DoF optimization to enhance the radar's z-axis accuracy and rolling contact modeling to make the leg kinematics robust. |
| [RIs-Calib: An Open-Source Spatiotemporal Calibrator for Multiple 3-D Radars and IMUs Based on Continuous-Time Estimation](https://ieeexplore.ieee.org/abstract/document/10816177) | [Code](https://github.com/Unsigned-Long/RIs-Calib) | IEEE Transactions on Instrumentation and Measurement  | 2024 | Solves infrastructure-free spatiotemporal calibration for multi-radar/multi-IMU systems by first initializing parameters using continuous-time B-splines and then refining them via global batch optimization.|
| [Advancements in Radar Odometry](https://ieeexplore.ieee.org/abstract/document/10802141) | N/A | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Improves a state-of-the-art radar odometry pipeline by introducing Gaussian smoothing and ICP alignment for better local scene understanding, and validates its enhanced accuracy through the first-ever comprehensive benchmark on the Boreas dataset.|
| [Enhancing Doppler Ego-Motion Estimation: A Temporally Weighted Approach to RANSAC](https://ieeexplore.ieee.org/abstract/document/10636553) | [Code](https://github.com/samuelLovett/tempEgo) | IEEE Sensors Applications Symposium (SAS) | 2024 | Addresses high outlier rates in Doppler ego-motion estimation by modifying RANSAC to use a temporally weighted sliding window, giving higher priority to more recent measurements. |
| [Radar4Motion: IMU-Free 4D Radar Odometry With Robust Dynamic Filtering and RCS-Weighted Matching](https://ieeexplore.ieee.org/abstract/document/10715681) | [Code](https://github.com/ailab-hanyang/Radar4Motion) |  IEEE Transactions on Intelligent Vehicles | 2024 | Achieves IMU-free radar odometry by leveraging Doppler data for initial ego-motion estimation and RCS values to weight points during scan-to-submap matching, addressing data sparsity. |
| [Multi-Target Device-Free Positioning Based on Spatial-Temporal mmWave Point Cloud](https://ieeexplore.ieee.org/abstract/document/10705685) | [Code](https://github.com/jinyu1024/DFP-Dataset) | IEEE Transactions on Mobile Computing | 2024 | Solves the challenge of multi-target device-free positioning by using a spatial-temporal clustering method and a gait-based particle filter to associate and track identities from fine-grained mmWave point clouds. |
| [Do we need scan-matching in radar odometry?](https://ieeexplore.ieee.org/abstract/document/10610666) | [Code](https://github.com/kubelvla/mine-and-forest-radar-dataset) | IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Demonstrates that for 4D radar, odometry derived from the direct integration of Doppler and IMU data can be similar or superior to traditional 3D scan registration, especially in feature-sparse environments. |
| [Traj-LO: In Defense of LiDAR-Only Odometry Using an Effective Continuous-Time Trajectory](https://ieeexplore.ieee.org/abstract/document/10387726) | [Code](https://github.com/kevin2431/Traj-LO) | IEEE Robotics and Automation Letters | 2024 | Improves LiDAR-only odometry by using a continuous-time trajectory representation that effectively handles motion distortion and allows for accurate pose interpolation between scans. |
| [Doppler-only Single-scan 3D Vehicle Odometry](https://ieeexplore.ieee.org/abstract/document/10611199) | [Code](https://github.com/andresgalu/doppler_odometry) | IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Achieves vehicle odometry using only Doppler velocity measurements from a single radar scan by formulating a novel optimization problem that estimates 3D motion without relying on point cloud registration. |
| [MS-VRO: A Multistage Visual-Millimeter Wave Radar Fusion Odometry](https://ieeexplore.ieee.org/abstract/document/10530463) | [Code](https://github.com/thucyw/MS-VRO) |IEEE Transactions on Robotics | 2024 | Solves monocular VO's scale ambiguity, scale drift, and dynamic environment errors by deeply fusing mmWave radar data at multiple distinct stages: initialization, joint optimization, and feature selection. |
| [MSC-RAD4R: ROS-Based Automotive Dataset With 4D Radar](https://ieeexplore.ieee.org/abstract/document/10225273) | [Dataset](https://mscrad4r.github.io/urban/overall/) | IEEE Robotics and Automation Letters | 2023 | Addresses the lack of sufficient odometry sensors in existing 4D radar datasets by releasing a new, comprehensive dataset (MSC-RAD4R) specifically designed to support robust radar SLAM/odometry research. |
| [milliEgo: Single-chip mmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion](https://arxiv.org/abs/2006.02266) | [Code](https://github.com/ChristopherLu/milliEgo) | SenSys | 2020 | Addresses the brittleness of traditional registration on sparse, single-chip radar data by proposing a deep architecture optimized for sparse pose transformation and a mixed-attention module for robust sensor fusion.|


### Multi-Object Tracking

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Asynchronous Data Fusion With Randomly Delayed Measurements for Lane-Level Vehicle Tracking in Tunnel Environment](https://ieeexplore.ieee.org/abstract/document/10938792) | [Code](https://github.com/futianxuan/data) | IEEE Transactions on Intelligent Transportation Systems | 2025 | Tackles unreliable lane-level vehicle tracking in tunnels by using a Bayesian weight mixture filter to fuse asynchronous, randomly delayed measurements from MMW radar and magnetic sensors. |
| [USVTrack: USV-Based 4D Radar-Camera Tracking Dataset for Autonomous Driving in Inland Waterways](https://arxiv.org/abs/2506.18737) | [Dataset](https://github.com/USVTrack/USVTrack) | arXiv | 2025 | Provides the first 4D radar-camera tracking dataset for inland waterway autonomous navigation featuring unique challenges of water surface reflections. |
| [Real-Time Multi-object Tracking and Identification Using Sparse Point-Cloud Data from Low-Cost mmWave Radar](https://link.springer.com/chapter/10.1007/978-3-031-92011-0_12) | N/A | Robot Intelligence Technology and Applications | 2024 | Enables real-time multi-object tracking from sparse mmWave point clouds through efficient data association algorithms optimized for low-cost radar sensors. |


### Simultaneous Localization and Mapping (SLAM)

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Doppler-SLAM: Doppler-Aided Radar-Inertial and LiDAR-Inertial SLAM](https://arxiv.org/abs/2504.11634) | [Code](https://github.com/Wayne-DWA/Doppler-SLAM) | IEEE Robotics and Automation Letters | 2025 | Enhances SLAM accuracy by integrating Doppler velocity measurements into radar-inertial and LiDAR-inertial frameworks to provide additional motion constraints. |
| [S^3E: Self-Supervised State Estimation for Radar-Inertial System](https://arxiv.org/abs/2509.25984) | N/A | arXiv | 2025 | Achieves self-supervised radar-inertial state estimation by learning motion patterns from unlabeled data to reduce dependency on ground truth annotations. |
| [MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction](https://arxiv.org/abs/2508.15653) | [Code](https://github.com/2004yan/MapKD2026) | arXiv | 2025 | Enables efficient online HD map construction by distilling knowledge from offline maps using cross-modal learning to reduce computational overhead. |
| [Towards Dense and Accurate Radar Perception via Efficient Cross-Modal Diffusion Model](https://ieeexplore.ieee.org/document/10592769) | [Code](https://github.com/ZJU-FAST-Lab/Radar-Diffusion) | IEEE Robotics and Automation Letters | 2024 | Generates dense radar representations from sparse measurements using cross-modal diffusion models that leverage complementary sensor information for accurate perception. |
| [Radarize: Enhancing Radar SLAM with Generalizable Doppler-Based Odometry](https://dl.acm.org/doi/10.1145/3643832.3661871) | [Project](https://radarize.github.io/) | ACM International Conference on Mobile Systems, Applications, and Services (MobiSys) | 2024 | Introduces a self-contained, radar-only SLAM system that significantly outperforms existing radar-inertial methods by leveraging Doppler-based odometry and multipath suppression, eliminating the need for any auxiliary sensors. |
| [Enhancing mmWave Radar Point Cloud via Visual-inertial Supervision](https://ieeexplore.ieee.org/document/10610091) | [Code](https://github.com/ClarenceZSK/mmEMP) | IEEE International Conference on Robotics and Automation (ICRA) | 2024| Replaces expensive LiDAR supervision with a low-cost visual-inertial system to densify radar point clouds and remove artifacts, making high-quality radar enhancement accessible for commercial vehicles.|
| [RaNDT SLAM: Radar SLAM Based on Intensity-Augmented Normal Distributions Transform](https://ieeexplore.ieee.org/document/10802458) | [Code](https://github.com/IGMR-RWTH/RaNDT-SLAM) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Tackles the slowness of radar SLAM in noisy environments by augmenting the Normal Distributions Transform (NDT) with radar intensity information for faster and more accurate registration. |
| [A Deep Automotive Radar Detector Using the RaDelft Dataset](https://ieeexplore.ieee.org/abstract/document/10731871) | [Dataset](https://github.com/RaDelft/RaDelft-Dataset) | IEEE Transactions on Radar Systems | 2024 | Uses synchronized lidar data as ground truth to train a neural network that generates shape-preserving, lidar-like point clouds from only radar data. |
| [mmPlace: Robust Place Recognition With Intermediate Frequency Signal of Low-Cost Single-Chip Millimeter Wave Radar](https://ieeexplore.ieee.org/abstract/document/10472597) | [Code](https://github.com/TC-MCZ/mmPlace) | IEEE Robotics and Automation Letters  | 2024 | Achieves robust place recognition using intermediate frequency signals from low-cost single-chip mmWave radar by extracting stable features that are invariant to environmental changes. |
| [BatMobility: Towards Flying Without Seeing for Autonomous Drones](https://dl.acm.org/doi/10.1145/3570361.3592532) | [Project](https://batmobility.github.io/) | ACM MobiCom | 2023 | Enables drones to 'fly without seeing' by introducing a radar-only perception system that uses a novel 'radio flow' technique as a robust, non-optical alternative to optical flow for navigation. |
| [Cross-Modal Contrastive Learning of Representations for Navigation using Lightweight, Low-Cost Millimeter Wave Radar for Adverse Environmental Conditions](https://ieeexplore.ieee.org/document/9362209) | [Project](https://arg-nctu.github.io/projects/deeprl-mmWave.html) | IEEE Robotics and Automation Letters | 2021 | Enables robust, radar-only reinforcement learning navigation in adverse conditions by using cross-modal contrastive learning to align sparse radar representations with clean LiDAR data during the training phase. |

### Sensor Fusion Techniques

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [HENet++: Hybrid Encoding and Multi-task Learning for 3D Perception and End-to-end Autonomous Driving](https://arxiv.org/abs/2511.07106) | [Code](https://github.com/Tsinghua-MARS-Lab/Occ3D) | arXiv | 2025 | Addresses the high computational cost and conflicting feature needs of multi-task 3D perception by using a hybrid encoding scheme (large encoder for recent frames, small encoder for older frames) to efficiently extract both dense and sparse features. |
| [Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion](https://arxiv.org/abs/2511.00859) | [Code](https://github.com/detxter-jvb/Layer-Wise-Modality-Decomposition) | Conference on Neural Information Processing Systems (NeurIPS) | 2025 | Addresses the lack of interpretability in multi-sensor fusion models by proposing a post-hoc, model-agnostic method that decomposes the network layer by layer to attribute the final prediction to each individual input modality. |
| [Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera](https://arxiv.org/abs/2503.07029) | [Code](https://github.com/kaist-avelab/K-Radar/blob/main/docs/sensor_fusion.md) | arXiv | 2025 | Addresses the vulnerability of multi-sensor fusion systems to sensor failure by projecting all sensor data into a unified representation, enabling robust cross-modal attention that is aware of sensor availability.|
| [Radar and Event Camera Fusion for Agile Robot Ego‚ÄëMotion Estimation](https://arxiv.org/abs/2506.18443) | [Code](https://github.com/ZzhYgwh/TwistEstimator) | arXiv | 2025 | Proposes an IMU‚Äëfree, feature‚Äêassociation‚Äëfree fusion of event camera and millimetre‚Äêwave radar Doppler to directly estimate 6‚ÄëDOF velocity of agile robots under high‚Äëmotion conditions, bypassing traditional frame matching. |
| [Radar‚ÄëBased NLoS Pedestrian Localization for Darting‚ÄëOut Scenarios Near Parked Vehicles with Camera‚ÄëAssisted Point Cloud Interpretation](https://arxiv.org/abs/2508.04033) | [Project](https://hiyeun.github.io/NLoS/) | arXiv | 2025 | Tackles unexpected pedestrian appearance in NLoS urban parking‚Äëvehicle blind spots by fusing monocular camera segmentation and depth estimation of parked vehicles with 2D radar point‚Äëcloud data to accurately localize the pedestrian early. |
| [VR-PCT: Enhanced VR Semantic Performance via Edge-Client Collaborative Multi-modal Point Cloud Transformers](https://ieeexplore.ieee.org/abstract/document/11153865) | [Code](https://github.com/luoyumei1-a/VR-PCT) | IEEE Transactions on Mobile Computing | 2025 | Reduces data overhead in multi-modal VR by using an edge-client collaborative framework where the client transmits only the "semantic region" of the visual data, not the full video, to the edge for fusion with radar. |
| [Talk2PC: Enhancing 3D Visual Grounding through LiDAR and Radar Point Clouds Fusion for Autonomous Driving](https://arxiv.org/abs/2503.08336)| [Code](https://github.com/GuanRunwei/TPCNet) | arXiv | 2025 | Achieves prompt-guided 3D visual grounding by introducing a two-stage adaptive fusion framework that combines LiDAR and 4D radar, using cross-attention and graph fusion to locate the queried object. |
| [V2XScenes: A Multiple Challenging Traffic Conditions Dataset for Large-Range Vehicle-Infrastructure Collaborative Perception](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_V2XScenes_A_Multiple_Challenging_Traffic_Conditions_Dataset_for_Large-Range_Vehicle-Infrastructure_ICCV_2025_paper.pdf) | [Project](https://advrc-wangbw.github.io/V2XScenes/) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Addresses the lack of benchmark data for V2X perception in occluded scenarios by releasing a dataset that uniquely provides consistent, global object tracking IDs across successive road sections. |
| [4D mmWave Radar for Sensing Enhancement in Adverse Environments: Advances and Challenges](https://arxiv.org/abs/2503.24091) | [Code](https://github.com/XiangyPeng/4D-mmWave-Radar-in-Adverse-Environments) | arXiv | 2025 | Fills a research gap by providing the first comprehensive review of 4D mmWave radar datasets and learning-based methods specifically for perception in adverse environments. |
| [Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera](https://arxiv.org/abs/2503.07029) | [Code](https://github.com/kaist-avelab/K-Radar) | arXiv | 2025 | Addresses the vulnerability of multi-sensor fusion systems to sensor failure by projecting all sensor data into a unified representation, enabling robust cross-modal attention that is aware of sensor availability. |
| [RadarRGBD: A Multi-Sensor Fusion Dataset for Perception with RGB-D and mmWave Radar](https://arxiv.org/abs/2505.15860) | [Dataset](https://github.com/song4399/RadarRGBD) | arXiv | 2025 | Provides a comprehensive RGB-D and mmWave radar fusion dataset enabling research on complementary depth sensing and material property estimation. |
| [MIPD: A Multi-Sensory Interactive Perception Dataset for Embodied Intelligent Driving](https://ieeexplore.ieee.org/abstract/document/11112801) | [Code](https://github.com/BUCT-IUSRC/Dataset__MIPD) | IEEE Transactions on Intelligent Transportation Systems | 2025 | Addresses the lack of embodied sensory information in autonomous driving datasets by introducing a new dataset (MIPD) that integrates sound, light, and vibration with traditional sensors to foster more interactive and comprehensive perception. |
| [Artemis: Contour-Guided 3-D Sensing and Localization With mmWave Radar for Infrastructure-Assisted AVs](https://ieeexplore.ieee.org/document/10891135) | N/A | IEEE Internet of Things Journal | 2025 | Achieves precise infrastructure-based localization by using mmWave radar to extract object contours that guide 3D sensing and vehicle positioning. |
| [CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars](https://www.arxiv.org/abs/2508.16030) | [Code](https://github.com/John1001Song/FMCW_Vehicle_Fusion) | arXiv | 2025 | Enables cooperative perception among vehicles by sharing and fusing mmWave FMCW radar data to expand sensing coverage and reduce occlusions. |
| [Ultra-High-Frequency Harmony: mmWave Radar and Event Camera Orchestrate Accurate Drone Landing](https://dl.acm.org/doi/10.1145/3715014.3722048) | [Project](https://mme-loc.github.io/) | SenSys | 2025 | Achieves precise drone landing by fusing mmWave radar range measurements with event camera's high-temporal-resolution motion detection capabilities. |
| [Rehearse-3d: A Multi-Modal Emulated Rain Dataset for 3d Point Cloud De-Raining](https://arxiv.org/abs/2504.21699) | [Dataset](https://sporsho.github.io/REHEARSE3D) | arXiv | 2025 | Provides multi-modal rainy weather dataset enabling research on point cloud de-raining algorithms for robust perception under adverse conditions. |
| [4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision](https://arxiv.org/abs/2505.13905) | [Code](https://github.com/CLASS-Lab/4D-ROLLS) | arXiv | 2025 | Learns 4D radar occupancy representations using LiDAR as supervisory signal to overcome radar annotation challenges and enable dense scene understanding. |
| [MIPD: A Multi-Sensory Interactive Perception Dataset for Embodied Intelligent Driving](https://ieeexplore.ieee.org/abstract/document/11112801) | [Dataset](https://github.com/BUCT-IUSRC/Dataset__MIPD) | IEEE Transactions on Intelligent Transportation Systems | 2025 | Provides multi-sensory dataset capturing driver-vehicle interactions for research on embodied intelligence and driver monitoring systems. |
| [MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies](https://arxiv.org/abs/2501.15384) | [Code](https://github.com/LucasYang567/MetaOcc) | arXiv | 2025 | Predicts 3D occupancy by fusing surround-view 4D radar and camera through spatio-temporal networks with dual training strategies for improved generalization. |
| [Multi-Modal Fusion Sensing: A Comprehensive Review of Millimeter-Wave Radar and Its Integration With Other Modalities](https://ieeexplore.ieee.org/document/10525189) | N/A | IEEE Communications Surveys & Tutorials | 2024 | Comprehensively surveys mmWave radar fusion with various modalities covering fusion architectures, challenges, and applications across different domains. |
| [A Deep Automotive Radar Detector using the RaDelft Dataset](https://arxiv.org/abs/2406.04723) | [Code](https://github.com/RaDelft/RaDelft-Dataset) | arXiv | 2024 | Uses synchronized lidar data as ground truth to train a neural network that generates shape-preserving, lidar-like point clouds from only radar data. |
| [Radar Meets Vision: Robustifying Monocular Metric Depth Prediction for Mobile Robotics](https://arxiv.org/abs/2410.00736) | [Code](https://github.com/ethz-asl/ti_mmwave_rospkg) | arXiv | 2024 | Solves the poor generalization of monocular depth estimation in low-texture robotics environments by encoding sparse mmWave radar data into the vision model's input.|
| [CARB-Net: Camera-Assisted Radar-Based Network for Vulnerable Road User Detection](https://link.springer.com/chapter/10.1007/978-3-031-73039-9_17) | [Code](https://github.com/weiyulee/RadVRU) | European Conference on Computer Vision (ECCV) | 2024 | Addresses radar's poor angular resolution in VRU detection by fusing camera information into the early stages of a radar network, using a context learning approach to ensure graceful degradation. |
| [A Resource Efficient Fusion Network for Object Detection in Bird's-Eye View using Camera and Raw Radar Data](https://ieeexplore.ieee.org/abstract/document/10919729) | [Code](https://github.com/tue-mps/refnet) | IEEE 27th International Conference on Intelligent Transportation Systems | 2024 | Solves the problem of radar sparsity by bypassing point clouds, instead fusing decoded Range-Azimuth (RA) features (from the raw RD spectrum) with camera features transformed into the BEV Polar domain.|
| [NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and Mapping](https://arxiv.org/abs/2309.00962) | [Dataset](https://github.com/junzhang2016/NTU4DRadLM) | arXiv | 2023 | Addresses the lack of multi-modal datasets for robust SLAM by releasing NTU4DRadLM, the first 6-sensor dataset (including 4D radar and thermal) specifically designed for localization with ground-truth odometry and loop closures. |
| [Echoes Beyond Points: Unleashing the Power of Raw Radar Data in Multi-modality Fusion](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a8f7f12b29d9b8c227785f6b529f63b7-Abstract-Conference.html) | [Code](https://github.com/tusen-ai/EchoFusion) | Conference on Neural Information Processing Systems (NeurIPS) | 2023 | Bypasses sparse, suboptimal point clouds by fusing rich, lossless distance and speed features from the raw radar spectrum directly with image features in Bird's-Eye View (BEV). |
| [The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset](https://arxiv.org/abs/1909.01300) | [Dataset](https://github.com/oxford-robotics-institute/radar-robotcar-dataset-sdk) | arXiv | 2019 | Extends the popular Oxford RobotCar dataset with a high-resolution scanning radar to provide the research community with a large-scale, multi-sensor dataset for developing autonomous driving perception algorithms that are robust to adverse weather. |

### Point Cloud Processing
| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent Diffusion](https://arxiv.org/abs/2511.07067) | N/A | arXiv | 2025 | Generates high-resolution 3D radar point clouds from low-resolution inputs using a latent diffusion model that captures complex spatial structures and noise characteristics of radar data. |
| [CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation](https://arxiv.org/abs/2511.01383) | [Code](https://github.com/Soldann/CaRLi-V) | arXiv | 2025 | Estimates dense 3D point-wise velocity via a closed-form solution that combines radial velocity from a novel raw radar "velocity cube," tangential velocity from optical flow, and range from LiDAR. |
| [RaCalNet: Radar Calibration Network for Sparse‚ÄëSupervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560) | [Code](https://github.com/818slam/RaCalNet) | arXiv | 2025 | Proposes a network to calibrate radar with sparse LiDAR supervision to produce metric depth estimation from radar and RGB with minimal dense supervision. :contentReference|
| [Triangulation of 3D target points from radar range and bearing data](https://openaccess.thecvf.com/content/ICCV2025W/CroCoDL/html/Oskarsson_Triangulation_of_3D_target_points_from_radar_range_and_bearing_ICCVW_2025_paper.html)| [Code](https://github.com/hamburgerlady/radar-triangulation) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Solves the 3D radar triangulation problem by formulating the maximum likelihood estimation as an eigenvalue problem, allowing for the efficient extraction of the global optimum solution. |
| [Physics-Aware Gaussian Radar Enhancement for All-weather Perception](https://robogen-iros.github.io/accepted/15_Physics_Aware_Gaussian_Rada.pdf) | [Code](https://github.com/Suhani92/Physics-Aware-Radar-Enhancement) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2025 | Solves radar sparsity by modeling each detection as a 3D beam frustum, rather than an isolated point, and uses this physical prior to train a dual-stream network for dense point cloud enhancement. |
| [Radar-Mamba: 4D Millimeter-Wave Point Cloud Enhancement via State Space Models](https://dl.acm.org/doi/abs/10.1145/3746027.3755431) | N/A | MM | 2025 | Proposes a lightweight Mamba-based model that enhances sparse 4D radar data by efficiently capturing spatial-temporal features and integrating Doppler information, using LiDAR for supervision. |
| [RLCNet: A Novel Deep Feature-Matching-Based Method for Online Target-Free Radar-LiDAR Calibration](https://ieeexplore.ieee.org/abstract/document/11127342) | [Code](https://github.com/nubot-nudt/RLCNet) | IEEE International Conference on Robotics and Automation (ICRA) | 2025 | Tackles radar-LiDAR extrinsic calibration by using a deep network that first establishes sparse keypoint matches and then refines them into dense correspondences to overcome radar point cloud sparsity. |
| [RadarSplat: Radar Gaussian Splatting for High-Fidelity Data Synthesis and 3D Reconstruction of Autonomous Driving Scenes](https://arxiv.org/abs/2506.01379) | [Code](https://github.com/umautobots/radarsplat) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Overcomes the poor performance of neural representations in noisy radar scenarios by integrating Gaussian Splatting with a novel noise model, enabling high-fidelity 3D reconstruction and realistic data synthesis. |
| [NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds](https://openaccess.thecvf.com/content/CVPR2025W/WAD/html/Rafidashti_NeuRadar_Neural_Radiance_Fields_for_Automotive_Radar_Point_Clouds_CVPRW_2025_paper.html) | [Code](https://github.com/mrafidashti/neuradar) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2025 | Pioneers the use of Neural Radiance Fields for radar by proposing a model that jointly generates multi-sensor data and uses a probabilistic representation to accurately capture the stochastic nature of radar point clouds. |
| [MilliNoise: a Millimeter-wave Radar Sparse Point Cloud Dataset in Indoor Scenarios](https://dl.acm.org/doi/abs/10.1145/3625468.3652189) | [Dataset](https://github.com/c3lab/MilliNoise) | ACM Multimedia Systems Conference | 2024 | Addresses the lack of labeled training data for radar denoising by releasing MilliNoise, a large dataset where a motion capture system is used to accurately label every sparse point as "true" or "noise". |
| [RMap: Millimeter-Wave Radar Mapping Through Volumetric Upsampling](https://ieeexplore.ieee.org/abstract/document/10801827) | [Code](https://github.com/arpg/RMap) | IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 2024 | Addresses the severe sparsity and noise of radar data for 3D mapping by using a generative transformer to upsample, denoise, and fill in the point cloud to resemble a lidar map. |
| [RaViDeep: Target Detection Based on Deep Fusion of Radar and Vision in Berthing Scenarios](https://ieeexplore.ieee.org/abstract/document/10607951) | [Code](https://github.com/kagurua/RaViDeep) |  IEEE Transactions on Intelligent Vehicles | 2024 |Solves radar sparsity and image depth-deficiency by first using image semantics to densify radar points, and then using radar's accurate depth to guide image depth estimation, fusing both enhanced results for detection.|
| [A Recurrent CNN for Online Object Detection on Raw Radar Frames](https://ieeexplore.ieee.org/abstract/document/10547638) | [Code](https://github.com/colindecourt/record) | IEEE Transactions on Intelligent Transportation Systems | 2024 | Addresses the non-causal and computationally expensive nature of 3D convolution-based detectors by proposing a recurrent (ConvLSTM) architecture that enables efficient, causal (real-time) online object detection.|
| [MmWave Radar Point Cloud Segmentation using GMM in Multimodal Traffic Monitoring](https://ieeexplore.ieee.org/document/9114662) | [Code](https://github.com/radar-lab/traffic_monitoring) | IEEE International Radar Conference | 2020 | Solves the challenge of sparse data in radar traffic monitoring by using a high-resolution mmWave sensor and applying an unsupervised Gaussian Mixture Model (GMM) to a novel feature vector for point cloud segmentation. |

## ü©∫ Human Sensing & Healthcare

### Human Activity Recognition (HAR)

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [OG-PCL: Efficient Sparse Point Cloud Processing for Human Activity Recognition](https://arxiv.org/abs/2511.08910) | [Code](https://github.com/BlakeYan97/OG-PCL) | arXiv | 2025 | Proposes a lightweight parallel network (OG-PCL) that introduces an "Occupancy-Gated Convolution" (OGConv) block to provide an explicit compensation mechanism for handling sparse radar point clouds. |
| [OctoNet: A Large-Scale Multi-Modal Dataset for Human Activity Understanding Grounded in Motion-Captured 3D Pose Labels](https://neurips.cc/virtual/2025/loc/san-diego/poster/121376) | [Dataset](https://aiot-lab.github.io/OctoNet/) | Conference on Neural Information Processing Systems (NeurIPS) | 2025 | Fosters multi-modal human activity research by releasing a massive dataset (OctoNet) that uniquely uses motion-captured 3D pose labels as the high-fidelity ground truth for all 12 diverse sensor modalities. |
| [mmHSense: Multi-Modal and Distributed mmWave ISAC Datasets for Human Sensing](https://arxiv.org/pdf/2509.21396) | [Dataset](https://github.com/nisarnabeel/Multi-Modal-and-Distributed-mmWave-ISAC-Datasets-for-Human-Sensing/tree/main) | arXiv | 2025 | Releases a multi-modal mmWave ISAC dataset and demonstrates using parameter-efficient fine-tuning (PEFT) to adapt a single model to diverse human sensing tasks efficiently. |
| [Robust Cross-Domain RF-Based Multimodal Activity Recognition with Few-Shot Adaptation](https://ieeexplore.ieee.org/abstract/document/11205478) | [Code](https://github.com/qinzuan77-beep/code) | IEEE Internet of Things Journal  | 2025 | Solves poor cross-domain performance in multimodal RF (RFID, WiFi, mmWave) sensing by using a hybrid feature/decision fusion framework that dynamically weights each modality's contribution to enable rapid few-shot adaptation.|
| [Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition](https://arxiv.org/abs/2510.22772) | [Code](https://github.com/lab-emi/AIRHAR) | arXiv | 2025 | Solves the high computational cost of radar HAR on edge devices by proposing a parameter-efficient CNN (GateCNN) that uses dual-path gated convolutions to modulate Doppler features with temporal gates. |
| [Human Activity Recognition Based on Multipath Fusion in Non-line-of-sight Corner](https://ieeexplore.ieee.org/document/11177013) | [Code](https://github.com/tlz1111/Multipath-Fusion-Network) | IEEE Internet of Things Journal | 2025 | Achieves NLOS activity recognition by fusing multipath radar signals that bounce around corners to sense hidden human activities. |
| [Enhancing Activity Recognition: Motion Waveform Preprocessing from Millimeter-Wave Radar Data for Transformer-Based Classification](https://ieeexplore.ieee.org/document/11152068) | [Code](https://github.com/Alan-cs1/MmWave-Motion-Waveform-HAR) | IEEE International Conference on Multimedia and Expo Workshops (ICMEW) | 2025 | Improves transformer-based activity recognition by designing specialized preprocessing that extracts motion waveforms from mmWave radar signals. |
| [Resolution-Adaptive Micro-Doppler Spectrogram for Human Activity Recognition](https://arxiv.org/abs/2411.15057) | N/A | arXiv | 2025 | Enhances HAR performance by adaptively adjusting micro-Doppler spectrogram resolution based on activity characteristics and computational constraints. |
| [A Novel Multimodal LLM-Driven RF Sensing Method for Human Activity Recognition](https://ieeexplore.ieee.org/document/11003262) | [Code](https://github.com/ci4r/CI4R-MULTI3) | International Conference on Microwave, Antennas & Circuits (ICMAC) | 2025 | Leverages large language models to interpret multimodal RF sensing data by bridging radar signals with semantic understanding for improved activity recognition. |
| [RadMamba: Efficient Human Activity Recognition through Radar-based Micro-Doppler-Oriented Mamba State-Space Model](https://arxiv.org/abs/2504.12039) | [Code](https://github.com/lab-emi/AIRHAR) | arXiv | 2025 | Achieves efficient HAR using Mamba state-space models that capture micro-Doppler temporal dependencies with linear complexity for real-time processing. |
| [DGAR: A Unified Domain Generalization Framework for RF-Based Human Activity Recognition](https://arxiv.org/abs/2503.17667) | [Code](https://github.com/Junshuo-Lau/HUST_HAR_LFM) | arXiv | 2025 | Addresses cross-domain HAR challenges through unified domain generalization framework that learns domain-invariant radar representations. |
| [RadProPoser: Uncertainty-Aware Human Pose Estimation and Activity Classification from Raw Radar Data](https://arxiv.org/abs/2508.03578) | [Code](https://github.com/jonasmueler/RadProPoser) | arXiv | 2025 | Jointly performs pose estimation and activity classification from raw radar with uncertainty quantification to improve reliability in ambiguous scenarios. |
| [RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator](https://arxiv.org/abs/2509.06751) | [Code](https://github.com/JoeyBGOfficial/RadHARSimulatorV1-Model-Based-FMCW-Radar-Human-Activity-Recognition-Simulator) | arXiv | 2025 | Overcomes the challenge of acquiring diverse, high-fidelity radar data for Human Activity Recognition (HAR) by developing a model-based simulator that generates realistic micro-Doppler signatures for various activities.|
| [Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition](https://arxiv.org/abs/2504.02778) | [Code](https://github.com/Gbouna/MAK-GCN) | arXiv | 2025 | Addresses the limitation of fixed graph kernels for sparse point clouds by proposing a multi-head module that generates multiple, dynamic kernels, each adapting to different aspects of the local neighborhood's geometry. |
| [Few-Shot Adaptation to Unseen Conditions for Wireless-Based Human Activity Recognition Without Fine-Tuning](https://ieeexplore.ieee.org/abstract/document/10681641) | N/A | IEEE Transactions on Mobile Computing | 2024 | Eliminates the need for fine-tuning in wireless activity recognition by using meta-learning to learn a condition-invariant latent space, where recognition is performed based on activity similarity rather than a condition-dependent mapping. |
| [Hood: Real-time human presence and out-of-distribution detection using fmcw radar](https://ieeexplore.ieee.org/abstract/document/10789192) | N/A | IEEE Transactions on Radar Systems | 2024 | Simultaneously tackles human presence and out-of-distribution detection by using a reconstruction-based architecture on radar images to differentiate humans-with-clutter from clutter-only scenes. |
| [Advanced Millimeter-Wave Radar System for Real-Time Multiple-Human Tracking and Fall Detection](https://www.mdpi.com/1424-8220/24/11/3660) | [Code](https://github.com/DarkSZChao/MMWave_Radar_Human_Tracking_and_Fall_detection) | Sensors Journal | 2024 | Proposes a three-radar fusion framework that uses SNR-based dynamic DBSCAN clustering and a probability matrix to achieve robust multi-person tracking and fall detection.|
| [Resolution-Adaptive Micro-Doppler Spectrogram for Human Activity Recognition](https://arxiv.org/abs/2411.15057) | [Code](https://github.com/Signal-Park/Activity-Dependent-Spectrogram) | arXiv | 2024 | Addresses the limitation of fixed, linear spectrogram resolution by nonlinearly transforming the time-frequency representation to adaptively focus on the most relevant micro-Doppler frequency ranges. |
| [4D radar simulator for human activity recognition](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/rsn2.12468) | [Code](https://github.com/JASONZ777/4D_radar_simulator_PointNet) | IET Radar, Sonar & Navigation | 2024 | Overcomes the high cost of prototyping 4D radar for HAR by building an end-to-end simulator that uses a motion capture dataset to generate point clouds for algorithm benchmarking. |
| [A Dataset for Multi-intensity Continuous Human Activity Recognition through Passive Sensing](https://arxiv.org/abs/2407.21125) | [Code](https://github.com/arghasen10/mmdoppler) | arXiv | 2024 | Solves the failure of mmWave radar to capture micro-scale activities (like typing) by using an adaptive Doppler resolution processing pipeline to enhance signal precision. |
| [Fast Human Action Recognition via Millimeter Wave Radar Point Cloud Sequences Learning](https://dl.acm.org/doi/abs/10.1145/3627673.3679787) | [Code](https://github.com/Feiyuyu0503/FastHAR) | ACM International Conference on Information and Knowledge Management | 2024 | Solves the problem of processing sparse radar point clouds on resource-constrained devices by using a two-stage feature extractor that first builds local graphs with self-attention (to handle sparsity) and then uses 3D convolution to reduce sequence length before temporal modeling. |
| [XRF55: A Radio Frequency Dataset for Human Indoor Action Analysis](https://dl.acm.org/doi/abs/10.1145/3643543) | [Dataset](https://github.com/aiotgroup/XRF55-repo) | Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies | 2024 | Addresses the lack of diverse, large-scale RF datasets by releasing XRF55, which uniquely combines three distinct RF modalities (RFID, Wi-Fi, mmWave) and Kinect ground truth across 55 action classes |
| [Attention-Refined Unrolling for Sparse Sequential Micro-Doppler Reconstruction](https://ieeexplore.ieee.org/abstract/document/10543012) | [Code](https://github.com/rmazzier/STAR) | IEEE Journal of Selected Topics in Signal Processing  | 2024 | Solves the problem of slow and inaccurate micro-Doppler reconstruction from highly sparse JCS measurements by combining a single unrolled hard-thresholding layer with an attention mechanism for refinement. |
| [CubeLearn: End-to-end Learning for Human Motion Recognition from Raw mmWave Radar Signals](https://ieeexplore.ieee.org/document/10018429) | [Code](https://github.com/zhaoymn/cubelearn) | IEEE Internet of Things Journal | 2023 | Replaces the conventional, fixed DFT preprocessing in radar-based motion recognition with a learnable, end-to-end module to extract task-optimized features directly from raw signals, boosting performance especially for lightweight models. |
| [MiliPoint: a point cloud dataset for mmWave radar](https://dl.acm.org/doi/10.5555/3666122.3668861) | [Dataset](https://github.com/yizzfz/MiliPoint) | Conference on Neural Information Processing Systems (NeurIPS) | 2023 | Fosters research into point-based deep learning for radar by releasing a large-scale, diverse dataset for human activity recognition, complete with established performance baselines. |
| [MM-Fi: multi-modal non-intrusive 4D human dataset for versatile wireless sensing](https://dl.acm.org/doi/abs/10.5555/3666122.3666944) | [Dataset](https://github.com/ybhbingo/MMFi_dataset) | Conference on Neural Information Processing Systems (NeurIPS) | 2023 | Provides a large-scale multi-modal dataset combining 4D radar, RGB-D, and motion capture data to facilitate research in wireless human sensing. |
| [On Edge Human Action Recognition Using Radar-Based Sensing and Deep Learning](https://ieeexplore.ieee.org/abstract/document/10284529) | [Code](https://github.com/cosmiclabunige/ActionRecognition) | IEEE Transactions on Industrial Informatics | 2023 | Achieves real-time human action recognition on an edge device by feeding radar Range-Doppler maps into a deep neural network, specifically evaluating the accuracy and computational cost tradeoff for deployment.|

### Gesture Recognition & Hand Tracking
| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [RF-Behavior: A Multimodal Radio-Frequency Dataset for Human Behavior and Emotion Analysis](https://arxiv.org/abs/2511.06020) | [Dataset](https://www.kaggle.com/datasets/anonymizers/rf-behavior-dataset) | arXiv | 2025 | Addresses the lack of a comprehensive RF dataset by releasing RF-Behavior, which uniquely spans gestures, activities, and emotions using 13 radars and RFID, all grounded by precise motion-capture. |
| [Real-Time Human‚ÄìDrone Interaction via Active Multimodal Gesture Recognition Under Limited Field of View in Indoor Environments](https://ieeexplore.ieee.org/abstract/document/11181055) | [Code](https://github.com/fangweicheng6/Gesture-HDI) | IEEE Robotics and Automation Letters  | 2025 | Overcomes sensor limitations (lighting, FoV) in drone gesture control by combining a lightweight image/point-cloud fusion network with an active perception controller that optimizes the sensor's FoV. |
| [Simulation-Based Radar Gesture Recognition Using Domain Adversarial Training](https://ieeexplore.ieee.org/abstract/document/11205040) | [Code](https://github.com/mklein2024/RadarConf2025) | IEEE Radar Conference | 2025 | Overcomes the lack of real radar data for gesture recognition by generating synthetic data with Blender/ray-tracing and using Domain-Adversarial training to bridge the sim-to-real gap. |
| [Venus: Generating Large-scale mmWave Radar Data via Few 2D Videos for Gesture Recognition While Lying Down](https://dl.acm.org/doi/abs/10.1145/3746027.3755399) | N/A | MM | 2025 | Solves the data scarcity problem for radar-based gesture recognition in lying postures by first using a spatio-temporal diffusion model to generate diverse gesture sequences and then a meta-learning network to adapt these into realistic radar signals, all from a few 2D videos. |
| [An Explainable Tiny-Fast Kolmogorov‚ÄìArnold Network for Gesture-Based Air Handwriting Recognition of Tifinagh Letters in Resource-Constrained IoT Device](https://ieeexplore.ieee.org/abstract/document/11215747) | [Code](https://github.com/Ism-ail11/XTiny-FastKAN) | IEEE Internet of Things Journal | 2025 | Fills a cultural and technical gap by creating the first real-time, air-handwriting recognition system for Tifinagh letters, using a novel, interpretable, and tiny Kolmogorov‚ÄìArnold Network (XTiny-FastKAN) designed for resource-constrained IoT devices. |
| [mmWave Radar-based Unsupervised Gesture Recognition via Image-Aligned Heterogeneous Domain Transfer](https://ieeexplore.ieee.org/document/11180134) | [Code](https://github.com/onlinehuazai/mmGesture) | IEEE Transactions on Mobile Computing | 2025 | Achieves unsupervised gesture recognition by aligning radar spectrograms with image features through heterogeneous domain transfer learning. |
| [mmPencil: Toward Writing-Style-Independent In-Air Handwriting Recognition via mmWave Radar and Large Vision-Language Model](https://dl.acm.org/doi/10.1145/3749504) | [Dataset](https://www.kaggle.com/datasets/mmpencil/mmpencil-dataset/data) | Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies | 2025 | Enables writing-style-independent in-air handwriting recognition by combining mmWave radar with vision-language models for semantic understanding. |
| [Human-Centered Fully Adaptive Radar for Gesture Recognition in Smart Environments](https://ieeexplore.ieee.org/abstract/document/11126867) | [Dataset](https://github.com/ci4r) | IEEE Transactions on Human-Machine Systems | 2025 | Develops fully adaptive radar that automatically adjusts parameters based on user behavior and environment for robust gesture recognition. |
| [mmEgoHand: Egocentric Hand Pose Estimation and Gesture Recognition with Head-mounted Millimeter-wave Radar and IMU](https://arxiv.org/abs/2501.13805) | [Code](https://github.com/WhisperYi/mmVR) | arXiv | 2025 | Achieves egocentric hand tracking by fusing head-mounted mmWave radar with IMU for VR/AR applications with minimal occlusion. |
| [mmDigit: A Real-Time Digit Recognition Framework in Air-Writing Using FMCW Radar](https://ieeexplore.ieee.org/document/10771807/) | [Dataset](https://github.com/Tjkjjc/gesture) | IEEE Internet of Things Journal | 2025 | Enables real-time in-air digit writing recognition using FMCW radar by tracking hand motion trajectories and extracting stroke patterns. |
| [mmHand: Toward Pixel-Level-Accuracy Hand Localization Using a Single Commodity mmWave Device](https://ieeexplore.ieee.org/document/10906525) | N/A | IEEE Internet of Things Journal | 2025 | Achieves pixel-level hand localization accuracy from single mmWave device by combining advanced signal processing with learning-based refinement. |
| [Hand Gesture Recognition With Uncertainty Awareness via FMCW Radar Sensing and Deep Learning](https://ieeexplore.ieee.org/abstract/document/11023089) | [Code](https://github.com/thetuantrinh/Hand-Gesture-Recognition) | IEEE Sensors Journal | 2025 | Addresses the lack of reliability in deep learning-based gesture recognition by introducing a model that quantifies its own prediction uncertainty using a combination of techniques like Monte Carlo dropout and deep ensembles. |
| [Rodar: Robust Gesture Recognition Based on mmWave Radar Under Human Activity Interference](https://ieeexplore.ieee.org/abstract/document/10533689) | [Code](https://github.com/Xlab2024/MvDeFormer) | IEEE Transactions on Mobile Computing | 2024 | Achieves robust gesture recognition under activity interference by disentangling hand gestures from body movements using multi-view deformable attention. |
| [Eat-Radar: Continuous Fine-Grained Intake Gesture Detection Using FMCW Radar and 3D Temporal Convolutional Network with Attention](https://ieeexplore.ieee.org/abstract/document/10342867) | [Dataset](https://github.com/Pituohai/Eat-Radar) |  IEEE Journal of Biomedical and Health Informatics  | 2024 | Achieves fine-grained, continuous detection of eating and drinking gestures by applying a 3D temporal convolutional network with attention to radar Range-Doppler data, validated on a new public dataset featuring diverse eating styles in realistic meal sessions. |
| [A Multimodal Video and Radar Fusion Framework for High-Accuracy Isolated Sign Language Recognition](https://dl.acm.org/doi/abs/10.1109/TMC.2023.3235935) | [Code](https://github.com/impressncsu/ICCV2025_MSLR) | IEEE Transactions on Mobile Computing | 2024 | Addresses inadequate multimodal fusion in sign language recognition by proposing a two-stage attention mechanism (statistical and contrastive) to deeply fuse sEMG and IMU signals by first selecting active features and then weighting them based on inter-modal information gain. |
| [GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition](https://www.computer.org/csdl/proceedings-article/mass/2023/243300a218/1RIEetqCvpC) | [Code](https://github.com/exitudio/GaitSADA) | International Conference on Mobile Ad Hoc and Smart Systems (MASS) | 2023 | Tackles the poor generalization of mmWave gait recognition by using a two-stage semi-supervised domain adaptation method that combines contrastive learning with consistency training to align spatial and temporal domain shifts. |
| [Towards Domain-Independent and Real-Time Gesture Recognition Using mmWave Signal](https://dl.acm.org/doi/10.1109/TMC.2022.3207570) | [Code](https://github.com/DI-HGR/cross_domain_gesture_dataset) | IEEE Transactions on Mobile Computing | 2023 | Achieves domain-independent, real-time gesture recognition by using a novel data augmentation framework to improve generalization and a spatial-temporal segmentation algorithm to enable continuous recognition.|
| [Physically-Interpretable Data Augmentation for Multi-Range Hand Gesture Recognition Using FMCW Radar Time Series](https://ieeexplore.ieee.org/abstract/document/10268257) | N/A | IEEE Transactions on Radar Systems | 2023 | Bypasses the complexity of augmenting raw radar data by instead extracting and manipulating physically interpretable time series (range, angle) to simulate new gesture variations. |

### Occupancy, Presence & Fall Detection
| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [MMWiLoc: A Multi‚ÄëSensor Dataset and Robust Device‚ÄëFree Localization Method Using Commercial Off‚ÄëThe‚ÄêShelf Millimeter Wave Wi‚ÄëFi Devices](https://arxiv.org/abs/2506.11540) | [Code](https://github.com/wowoyoho/MMWiLoc) | arXiv| 2025 | Introduces a synchronized multi‚Äësensor dataset (mmWave WiFi + 2.4‚ÄØGHz WiFi + radar) and a device‚Äëfree localization method achieving centimetre‚Äêlevel accuracy using commercial mmWave WiFi.|
| [P2MFDS: A Privacy‚ÄëPreserving Multimodal Fall Detection System for Elderly People in Bathroom Environments](https://arxiv.org/abs/2506.17332) | [Code](https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-System-for-Elderly-People-in-Bathroom-Environ) | arXiv | 2025 | Addresses fall‚Äëdetection for elderly in bathrooms by fusing multiple sensor modalities in a privacy‚Äëpreserving way to reliably detect falls in sensitive environments. |
| [Exploration of Low-Cost but Accurate Radar-Based Human Motion Direction Determination](https://arxiv.org/abs/2507.22567) | [Code](https://github.com/JoeyBGOfficial/Low-Cost-Accurate-Radar-Based-Human-Motion-Direction-Determination) | arXiv | 2025 | Achieves accurate motion direction estimation with low-cost radar by developing efficient algorithms that maximize information extraction from limited hardware. |
| [End-to-End Radar Human Segmentation with Differentiable Positional Encoding](https://eusipco2025.org/wp-content/uploads/pdfs/0000631.pdf) | N/A | EUSIPCO | 2025 | Performs end-to-end human segmentation from radar by introducing differentiable positional encodings that adapt to irregular radar point distributions. |
| [MVDoppler-Pose: Multi-Modal Multi-View mmWave Sensing for Long-Distance Self-Occluded Human Walking Pose Estimation](https://ieeexplore.ieee.org/abstract/document/11093407) | [Code](https://github.com/gogoho88/MVDoppler-Pose) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2025 | Estimates human poses at long distances under self-occlusion by fusing multi-view mmWave Doppler signatures across multiple radar perspectives. |
| [SelaFD:Seamless Adaptation of Vision Transformer Fine-tuning for Radar-based Human Activity Recognition](https://ieeexplore.ieee.org/document/10888271/) | [Code](https://github.com/wangyijunlyy/SelaFD) | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2025 | Seamlessly adapts pre-trained vision transformers to radar-based HAR through selective fine-tuning strategies that preserve learned representations. |
| [Advanced Millimeter-Wave Radar System for Real-Time Multiple-Human Tracking and Fall Detection](https://www.mdpi.com/1424-8220/24/11/3660) | [Code](https://github.com/DarkSZChao/MMWave_Radar_Human_Tracking_and_Fall_detection) | Sensors | 2024 | Enables real-time multi-human tracking and fall detection by developing advanced algorithms for handling multiple targets and detecting sudden motion changes. |
| [BSENSE: In-vehicle Child Detection and Vital Sign Monitoring with a Single mmWave Radar and Synthetic Reflectors](https://dl.acm.org/doi/abs/10.1145/3666025.3699352) | [Code](https://github.com/mtang724/BSENSE-in-cabin) | SenSys | 2024 | Detects in-vehicle child presence and monitors vital signs using synthetic reflectors to enhance radar signal coverage in confined cabin spaces. |
| [RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar](https://proceedings.neurips.cc/paper_files/paper/2024/hash/b81d83165e3145a2e7d33bb5e33ea913-Abstract-Conference.html) | [Code](https://github.com/Toytiny/RadarOcc) | Conference on Neural Information Processing Systems (NeurIPS) | 2024 |Bypasses sparse radar point clouds by processing the full 4D radar tensor directly, using sidelobe-aware sparsification and spherical encoding to manage noise and volume for 3D occupancy prediction.|
| [MMVR: Millimeter-Wave Multi-view Radar Dataset and Benchmark for Indoor Perception](https://link.springer.com/chapter/10.1007/978-3-031-72986-7_18) | [Dataset](https://zenodo.org/records/12611978) | European Conference on Computer Vision (ECCV) | 2024 | Addresses the scarcity of diverse, high-resolution indoor radar data by releasing a large-scale, multi-view, multi-room dataset (MMVR) with comprehensive annotations for benchmarking key perception tasks. |
| [Emergency Response Person Localization and Vital Sign Estimation Using a Semi-Autonomous Robot Mounted SFCW Radar](https://arxiv.org/abs/2305.15795) | [Code](https://ieee-dataport.org/open-access/multi-person-localization-and-vital-sign-estimation-radar-dataset) | IEEE Transactions on Biomedical Engineering | 2024 | Proposes a complete processing chain (using 2D-MUSIC) for a robot-mounted through-wall radar to detect, localize, and estimate vital signs, validating it on a new, challenging benchmark dataset. |
| [RDGait: A mmWave Based Gait User Recognition System for Complex Indoor Environments Using Single-chip Radar](https://dl.acm.org/doi/10.1145/3678552)| [Code](https://github.com/DQ-WDQ/RDGait) | Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies | 2024 | Solves multipath ghost interference in complex indoor environments by using a novel, prior-free ghost detection algorithm based only on velocity change patterns. |
| [Human Detection from 4D Radar Data in Low-Visibility Field Conditions](https://arxiv.org/abs/2404.05307) | N/A | IEEE International Conference on Robotics and Automation (ICRA) | 2024 | Improves human detection in low-visibility conditions by introducing a multi-view radar semantic segmentation (MVRSS) dataset and a novel architecture that fuses multi-view radar data for robust detection. |
| [mmFall: Fall Detection using 4D MmWave Radar and a Hybrid Variational RNN AutoEncoder](https://arxiv.org/abs/2003.02386) | [Code](https://github.com/radar-lab/mmfall) | arXiv | 2022 | DCircumvents the need for fall data collection by training a variational RNN autoencoder in a semi-supervised manner on only normal activities, detecting falls as anomalies in the radar signal. |


### Pose Estimation & Skeletal Tracking & Human Motion

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [RAPTR: Radar-based 3D Pose Estimation using Transformer](https://openreview.net/forum?id=4pUumnQxDG) | [Code](https://github.com/merlresearch/radar-pose-transformer) | Conference on Neural Information Processing Systems (NeurIPS) | 2025 | Overcomes the high cost of 3D labels by proposing a Transformer model that uses weak supervision (2D keypoints and 3D BBoxes) and a two-stage decoder with pseudo-3D deformable attention for pose estimation. |
| [Few-shot Human Motion Recognition through Multi-Aspect mmWave FMCW Radar Data](https://arxiv.org/abs/2501.11028) | [Code](https://github.com/MountainChenCad/channel-DN4) | arXiv | 2025 | Improves radar-inertial odometry for drone navigation in GNSS-denied environments by incorporating a barometer and using a robust m-estimator to more adaptively handle sensor outliers than binary filters. |
| [Learning to Analyze Human Skeletal by Radar‚ÄìCamera Supervision](https://ieeexplore.ieee.org/document/10930633) | [Code](https://github.com/zylofor/STC-HSANet) | Winter Conference on Applications of Computer Vision (WACV) | 2024 | Learns radar-based skeleton estimation through camera supervision that provides ground truth skeletal annotations during training. |
| [RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence](https://arxiv.org/abs/2504.09862) | [Project](https://inowlzy.github.io/RadarLLM/) | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 2024 | Empowers LLMs to interpret human motion from radar point clouds by developing specialized encoders and language-aligned representations. |
| [mmPose-FK: A forward kinematics approach to dynamic skeletal pose estimation using mmWave radars](https://ieeexplore.ieee.org/abstract/document/10382450) | N/A | IEEE Sensors Journal | 2024 | Addresses the instability (vibration) of joint estimations from noisy radar by integrating a forward kinematics (FK) mechanism directly into the deep learning model to enforce temporal consistency. |
| [Diffusion Model Is a Good Pose Estimator from 3D RF-Vision](https://link.springer.com/chapter/10.1007/978-3-031-72640-8_1) | [Code](https://fanjunqiao.github.io/mmDiff-site/) | European Conference on Computer Vision (ECCV) | 2024 | Solves inaccurate and inconsistent pose estimation from noisy radar by using a diffusion model that is guided by dedicated body-part feature extractors and structural priors to overcome miss-detections. |
| [SUPER: Seated Upper Body Pose Estimation using mmWave Radars](https://arxiv.org/abs/2407.02455) | [Project](https://super-2023-web.github.io/SUPER/) | arXiv | 2024 | Solves the conflicting radar signature problem (e.g., high-motion arms vs. low-motion torso) in seated pose estimation by using a dual-radar fusion algorithm to create complementary point clouds. |
| [mmHPE: Robust Multiscale 3-D Human Pose Estimation Using a Single mmWave Radar](https://ieeexplore.ieee.org/abstract/document/10707266) | [Code](https://github.com/bh6aol/mmHPE) | IEEE Internet of Things Journal | 2024 | Improves 3D pose estimation accuracy from sparse radar point clouds by introducing a multiscale feature extraction network that captures both local and global body structures. |
| [QRFPose: Query-Based 3D Pose Estimation using Radio Signals](https://ieeexplore.ieee.org/abstract/document/10827777) | [Code](https://github.com/Intelligent-Perception-Lab/HIBER) | International Conference on Wireless Communications and Signal Processing (WCSP) | 2024 | Addresses the limitations of divide-and-conquer methods by treating body joints as learnable queries that use deformable attention to adaptively aggregate features from sparse global and dense local RF regions. |
| [Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion](https://dl.acm.org/doi/10.5555/3639940.3639965) | [Code](https://github.com/ramdrop/utm)| EWSN | 2023 | Improves human detection in visually degraded conditions by fusing thermal and radar data using a novel uncertainty-guided method, which leverages Bayesian feature extraction to mitigate sensor-specific noise. |
| [Hawkeye: Hectometer-range Subcentimeter Localization for Large-scale mmWave Backscatter](https://dl.acm.org/doi/abs/10.1145/3581791.3596869) | [Code](https://github.com/smilelabkaist/Hawkeye) | MobiCom | 2023 | Achieves large-scale, sub-centimeter 3D localization by using a Van Atta array tag (to suppress multipath) and a novel algorithm that leverages spectral leakage for fine-grained positioning.|
| [mmSignature: Semi-supervised human identification system based on millimeter wave radar](https://www.sciencedirect.com/science/article/abs/pii/S0952197623011235) | [Code](https://github.com/mmSignature/mmSignature) | Engineering Applications of Artificial Intelligence | 2023 | Solves the high cost of manual data labeling by using a semi-supervised co-training framework that leverages the complementary information between radar point clouds and range-velocity maps to learn from unlabeled data. |
| [mmPose-NLP: A Natural Language Processing Approach to Precise Skeletal Pose Estimation Using mmWave Radars](https://ieeexplore.ieee.org/document/9723439) | [Code](https://github.com/radar-lab/mmPose-NLP) | IEEE Transactions on Neural Networks and Learning Systems | 2022 | Pioneers the estimation of a large number of skeletal key points from radar by uniquely framing the problem as a natural language processing task, where a sequence-to-sequence model interprets voxelized point clouds like text. |
| [mmBody Benchmark: 3D Body Reconstruction Dataset and Analysis for Millimeter Wave Radar](https://dl.acm.org/doi/10.1145/3503161.3548262) | [Project](https://chen3110.github.io/mmbody/index) | ACM MM | 2022 | Establishes a comprehensive benchmark for 3D body reconstruction by creating a large-scale dataset to systematically compare radar and cameras, revealing radar's superior accuracy to RGB but inferiority to depth under normal conditions, and its greater robustness in adverse weather. |
| [mRI: Multi-modal 3D Human Pose Estimation Dataset using mmWave, RGB-D, and Inertial Sensors](https://dl.acm.org/doi/10.5555/3600270.3602258) | [Project](https://sizhean.github.io/mri) | Conference on Neural Information Processing Systems (NeurIPS) | 2022 | Fills the gap in home-based health monitoring research by releasing a large-scale, multi-modal dataset (mRI) of rehabilitation exercises captured with synchronized mmWave, RGB-D, and inertial sensors.|
| [Fast and scalable human pose estimation using mmWave point cloud](https://dl.acm.org/doi/10.1145/3489517.3530522) | [Code](https://github.com/anonymousIoTresearcher/FUSE) | DAC | 2022 | Tackles the sparsity and data scarcity issues in mmWave pose estimation by combining a multi-frame representation with a meta-learning framework to enable rapid adaptation to unseen scenarios. |

### Vital Signs & Biometric Identification
| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented
Pseudo-Label and Noise Contrast](https://arxiv.org/abs/2511.08071) | [Code](https://github.com/RadarHRSensing/Radar-APLANC) | arXiv | 2025 | Solves the need for costly labeled data in radar heartbeat sensing by using an unsupervised, noise-contrastive framework that generates augmented pseudo-labels from the radar matrix itself. |
| [Remote Emotion Recognition Using Continuous-Wave Bio-Radar System](https://www.mdpi.com/1424-8220/24/5/1420) | [Code](https://github.com/ctsgouveia/RadarEmotions) | sensors | 2024 | Demonstrates that machine learning on vital signs from a non-contact Bio-Radar can match the emotion recognition accuracy of certified contact-based systems, enabling monitoring without subject awareness. |
| [CogPhys: Assessing Cognitive Load via Multimodal Remote and Contact-based Physiological Sensing](https://openreview.net/pdf?id=VJEcCMx16R) | [Code](https://github.com/AnirudhBHarish/CogPhys) | Conference on Neural Information Processing Systems (NeurIPS) | 2025 | English: Addresses the lack of data for remote cognitive load monitoring by introducing a large, multi-modal dataset (video, thermal, RF) and demonstrating that fusing remote physiological signals can achieve classification accuracy comparable to intrusive, contact-based sensors. |
| [LifWavNet: Lifting Wavelet-based Network for Non-contact ECG Reconstruction from Radar](https://arxiv.org/abs/2510.27692) | N/A | arXiv | 2025 | Addresses the limitations of fixed wavelet methods by using a learnable lifting wavelet network and a multi-resolution STFT loss to adaptively synthesize ECG waveforms from radar signals. |
| [Evidential Remote Physiological Measurement via Uncertainty-aware Fusion of Video and RF](https://dl.acm.org/doi/abs/10.1145/3746027.3754594) | N/A | MM | 2025 | olves the problem of suboptimal video-RF fusion by training each modality to predict its own uncertainty, enabling a dynamic fusion that intelligently weights each sensor based on its real-time reliability. |
| [FusionPhys: A Flexible Framework for Fusing Complementary Sensing Modalities in Remote Physiological Measurement](https://openaccess.thecvf.com/content/ICCV2025/papers/Ying_FusionPhys_A_Flexible_Framework_for_Fusing_Complementary_Sensing_Modalities_in_ICCV_2025_paper.pdf) | [Code](https://github.com/ChH-Ying/FusonPhys) | IEEE International Conference on Computer Vision (ICCV) | 2025 | Overcomes the limitations of single-sensor (e.g., camera) physiological measurement by proposing a framework that adaptively fuses heterogeneous modalities (visible, NIR, radar) based on their shared representation as time-varying signals.  |
| [From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data](https://arxiv.org/abs/2506.19358) | N/A | arXiv | 2025 | Tackles data scarcity in radar-based ECG recovery by using a transfer learning model that pre-trains on unlabeled radar data and only requires a few paired samples for fine-tuning, complemented by an algorithm that actively tracks the heart to ensure high-quality signal acquisition. |
| [Simulation for Noncontact Radar-Based Physiological Sensing Using Depth-Camera-Derived Human 3D Model with Electromagnetic Scattering Analysis](https://arxiv.org/abs/2507.13826) | N/A | arXiv | 2025 | Enhances the realism of radar-based physiological simulations by replacing simplified geometric models with actual human body shape and motion data captured by a depth camera.|
| [Enhanced sparse optimization approach for vital signal extraction from millimeter-wave radar](https://www.sciencedirect.com/science/article/abs/pii/S1746809425009577) | [Code](https://github.com/Z-H-XU/DCT-Vital-Signs) | Biomedical Signal Processing and Control | 2025 | Improves vital sign extraction from radar by using a sparse optimization framework based on the Discrete Cosine Transform (DCT), whose energy compaction properties enable better separation of weak and spectrally overlapping signals. |
| [ReBP: Short-Term Blood Pressure Estimation by Reconstructing PPG Signals Based on mmWave Radar](https://ieeexplore.ieee.org/document/11028948) | [Code](https://github.com/JialMa/ReBP) | IEEE Sensors Journal | 2025 | Estimates blood pressure by reconstructing PPG-like signals from mmWave radar that capture cardiovascular pulse wave characteristics. |
| [Atrial Fibrillation Detection via Contactless Radio Monitoring and Knowledge Transfer](https://www.nature.com/articles/s41467-025-59482-y) | [Code](https://github.com/yyuqin/Atrial-Fibrillation-Detection) | nature communications | 2025 | Detects atrial fibrillation from contactless radar monitoring by transferring knowledge from clinical ECG data to radar cardiac patterns. |
| [Hierarchical and Multimodal Data for Daily Activity Understanding](https://arxiv.org/abs/2504.17696) | [Dataset](https://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/) | arXiv | 2025 | Provides hierarchical multimodal dataset capturing daily activities with synchronized radar, video, and sensor data for comprehensive activity understanding. |
| [CardiacMamba: A Multimodal RGB-RF Fusion Framework with State Space Models for Remote Physiological Measurement](https://arxiv.org/abs/2502.13624) | [Code](https://github.com/WuZheng42/CardiacMamba) | arXiv | 2025 | Measures remote physiological signals by fusing RGB and RF modalities using Mamba models that efficiently capture temporal cardiac dynamics. |
| [RadEye: Tracking Eye Motion Using FMCW Radar](https://dl.acm.org/doi/10.1145/3706598.3713775) | N/A | Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems | 2025 | Tracks eye motion using FMCW radar by detecting minute movements through high-resolution Doppler analysis for non-contact gaze estimation. |
| [Realistic Facial Expression Reconstruction Using Millimeter Wave](https://ieeexplore.ieee.org/abstract/document/10904120) | N/A | IEEE Transactions on Mobile Computing | 2025 | Reconstructs realistic facial expressions from mmWave radar by learning mappings between radar signatures and detailed facial muscle movements. |
| [A Heart Rate Measurement Model Based on Koopman Predictors With FMCW Radar](https://ieeexplore.ieee.org/abstract/document/11122469) | [Code](https://github.com/licongsheng/HRKNet) | IEEE Transactions on Instrumentation and Measurement | 2025 | Introduces a Koopman theory-based deep model that improves radar heart rate measurement by explicitly separating and processing the signal's time-invariant and time-variant dynamics. |
| [AirECG: Contactless Electrocardiogram for Cardiac Disease Monitoring via mmWave Sensing and Cross-domain Diffusion Model](https://dl.acm.org/doi/abs/10.1145/3678550) | [Code](https://github.com/LangchengZhao/AirECG) | IMWUT/Ubicomp | 2024 | Enables accurate, contactless ECG reconstruction for cardiac patients by using a cross-domain diffusion model, whose iterative denoising process can synthesize abnormal waveforms, and a guidance mechanism to ensure high fidelity. |
| [radarODE: An ODE-Embedded Deep Learning Model for Contactless ECG Reconstruction from Millimeter-Wave Radar](https://arxiv.org/abs/2408.01672) | [Code](https://github.com/ZYY0844/radarODE-MTL) | arXiv | 2024 | Improves radar-to-ECG reconstruction by embedding an Ordinary Differential Equation (ODE) into the deep learning decoder, which provides a morphological prior of the ECG waveform to guide the model and enhance robustness against body movements. |
| [radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction](https://arxiv.org/abs/2410.08656) | [Code](https://github.com/ZYY0844/radarODE-MTL) | arXiv | 2024 | Improves the robustness of radar-based ECG reconstruction against noise by deconstructing the problem into a multi-task learning framework and using a novel gradient alignment strategy to manage conflicting optimization goals. |
| [Comprehensive mm-Wave FMCW Radar Dataset for Vital Sign Monitoring: Embracing Extreme Physiological Scenarios](https://arxiv.org/abs/2405.12659) | [Dataset](https://data.4tu.nl/datasets/48acba04-96bc-4131-b52f-9e18458ad92b/2) | arXiv | 2024 | Addresses the lack of diverse vital sign data by releasing the first mm-Wave radar dataset validated against a Polar H10, specifically including extreme physiological scenarios and participants with unique respiratory profiles. |
| [Wave Dynamic Time Warping Algorithm for Periodic Signal Similarity Estimation](https://ieeexplore.ieee.org/abstract/document/10784705) | [Code](https://github.com/eslivko/WaveDTW) | IEEE SENSORS | 2024 | Solves the poor alignment of periodic signals by proposing a segment-based DTW algorithm that uses a 2D feature vector (amplitude and phase) to align wave segments instead of the entire sequence. |
| [Transforming Cardiovascular Health: a Transformer-Based Approach to Continuous, Non-Invasive Blood Pressure Estimation via Radar Sensing](https://ieeexplore.ieee.org/abstract/document/10446988) | [Code](https://github.com/nastassiavysotskaya/BP_Transformer) | IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | 2024 | Achieves medically-certified (BHS/AAMI) blood pressure estimation by using a Transformer model to leverage the predictive power of historic radar-derived pressure wave information. |
| [Machine Learning for Healthcare Radars: Recent Progresses in Human Vital Sign Measurement and Activity Recognition](https://ieeexplore.ieee.org/document/10322785) | N/A |  IEEE Communications Surveys & Tutorials  | 2023 | Surveys the use of machine learning in radar-based healthcare, highlighting its role in enhancing traditional vital sign algorithms versus its foundational necessity for activity recognition. |
| [Equitable Plethysmography Blending Camera and 77 GHz Radar Sensing for Equitable, Robust Plethysmography](https://dl.acm.org/doi/10.1145/3528223.3530161) | [Code](https://github.com/UCLA-VMG/EquiPleth) | ACM Transactions on Graphics  | 2022 | Addresses the fundamental bias of camera-based heart-rate monitoring against darker skin tones by proposing a debiasing-oriented fusion framework that integrates complementary and fairer radar data. |

### Sleep Monitoring

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [Advancing sleep health equity through deep learning on large-scale nocturnal respiratory signals](https://www.nature.com/articles/s41467-025-64340-y) | [Code](https://github.com/zhuangzx1127/ResSleepNet) | nature communications | 2025 | Addresses inequitable access to sleep diagnostics by developing a robust deep learning framework that analyzes large-scale respiratory signals (including radar-derived ones via transfer learning) for scalable, remote sleep staging and apnea detection across diverse populations. |
| [RestAware: Non-Invasive Sleep Monitoring Using FMCW Radar and AI-Generated Summaries](https://arxiv.org/abs/2508.00848v1) | N/A | arXiv | 2025 | Develops a non-invasive sleep monitoring system that uses FMCW radar for posture classification and uniquely integrates a large language model to automatically generate human-readable summaries from the sleep data. |
| [A Robust and Accurate FMCW MIMO Radar Vital Sign Monitoring Framework With 4-D Cardiac Beamformer and Heart-Rate Trace Carving Technique](https://ieeexplore.ieee.org/document/10516282) | N/A | IEEE Transactions on Microwave Theory and Techniques | 2024 | Improves radar-based heart rate monitoring in low-SNR environments by using a 4-D beamformer to focus on the heart in both space and time-frequency, and a trace carving technique to reconstruct faint signals from noise. |
| [MiSleep: Human Sleep Posture Identification from Deep Learning Augmented Millimeter-wave Wireless Systems](https://dl.acm.org/doi/full/10.1145/3643866) | N/A | ACM Transactions on Internet of Things | 2023 | Achieves detailed sleep posture monitoring by predicting 3D body joint locations from radar, uniquely using a state machine to first detect toss-and-turn events and only performing the prediction during stable rest periods. |

### Fatigue driving detection

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [CarVision: Vehicle Ranging and Tracking Using mmWave Radar for Enhanced Driver Safety](https://www.computer.org/csdl/proceedings-article/percom/2025/355100a215/27fizQ2avXG) | [Code](https://github.com/srajib826/CarVision) | IEEE International Conference on Pervasive Computing and Communications (PerCom) | 2025 | Enhances driver safety by using mmWave radar for precise vehicle ranging and tracking to provide collision warnings and maintain safe distances. |
| [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172) | [Dataset](https://github.com/WJULYW/PhysDrive-Dataset) | arXiv | 2025 | Provides multimodal dataset for driver monitoring with synchronized physiological measurements enabling research on fatigue and distraction detection. |
| [A Driver Activity Dataset with Multiple RGB-D Cameras and mmWave Radars](https://dl.acm.org/doi/abs/10.1145/3625468.3652181) | [Code](https://www.kaggle.com/datasets/guanhualee/driver-activity-dataset) | ACM Multimedia Systems Conference | 2024 | Addresses the lack of fine-grained, non-fatigue driver activity data by releasing a comprehensive multi-modal (radar, RGB-D) and multi-angle (face, body, hands) dataset to enable privacy-conscious research. |
| [mmAssist:Passive Monitoring of Driver's Attentiveness Using mmWave Sensors](https://ieeexplore.ieee.org/abstract/document/10041297) | [Code](https://github.com/arghasen10/mmAssist) | International Conference on COMmunication Systems & NETworkS (COMSNETS) | 2023 | Addresses the invasive nature of camera-based monitoring by using Range-Doppler information from a non-invasive mmWave radar to classify driver attentiveness levels. |

### Identity Recognition & Person Re-identification

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [mmPPT: Hierarchical-Serialization-Enhanced Point Transformer for mmWave Pedestrian Reconstruction](https://www.sciencedirect.com/science/article/abs/pii/S1566253525008978) | N/A | Information Fusion | 2025 | Improves 3D pedestrian reconstruction from sparse radar by using a Point Transformer with a novel hierarchical serialization strategy that captures both fine-grained local details and global structural relationships. |
| [I Sense You Fast: Simultaneous Action and Identity Inference by Slimming Multi-Branch RadarNet](https://ieeexplore.ieee.org/document/11005642) | [Code](https://github.com/MagicalLiHua/PolyLite-RadarNet) | IEEE Transactions on Mobile Computing | 2025 | Achieves simultaneous action and identity recognition using slimmed multi-branch networks that efficiently share features across tasks for real-time inference. |
| [Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds](https://ieeexplore.ieee.org/document/11080220) | [Code](https://github.com/rmazzier/OpenSetGaitRecognition_PCAA) | IEEE Sensors Journal | 2025 | Performs open-set gait recognition from sparse radar point clouds by learning discriminative features that generalize to unseen identities. |
| [mmReID: Person Reidentification Based on Commodity Millimeter-Wave Radar](https://ieeexplore.ieee.org/document/10937945) | [Code](https://github.com/ci4r/mmReID) | IEEE Internet of Things Journal | 2025 | Enables person re-identification across camera views using commodity mmWave radar by extracting gait and body shape signatures. |
| [Through-Wall Cross-Domain User Identification via Lip Movement Micro-Doppler and MIMO Radar: an Unsupervised Domain Adaptation Approach](https://ieeexplore.ieee.org/abstract/document/11153694) | [Code](https://github.com/KaiYCode/Lip-TWCDID) | IEEE Transactions on Mobile Computing | 2025 | Achieves through-wall user identification by detecting lip movement micro-Doppler with MIMO radar and using domain adaptation across environments. | 
| [Causal Localization Network for Radar Human Localization With Micro-Doppler Signature](https://ieeexplore.ieee.org/abstract/document/10387441) | [Code](https://github.com/dbstjswo505/CLNet) | IEEE Access  | 2024 | Introduces the novel task of temporally localizing human identifications within untrimmed micro-Doppler signatures and proposes a baseline Causal Localization Network (CLNet) to solve it. |
| [Mission: mmWave Radar Person Identification with RGB Cameras](https://dl.acm.org/doi/abs/10.1145/3666025.3699340) | [Code](https://github.com/EverRaynor/Mission) | SenSys | 2024 | Proposes the first cross-modal ReID system that identifies a person in RGB images based on their detection by mmWave radar, using a novel similarity estimation to bridge the 3D-coarse (radar) to 2D-fine-grained (image) modal gap. |
| [Simultaneous Authentication of Multiple Users Using a Single mmWave Radar](https://ieeexplore.ieee.org/abstract/document/10414001) | N/A | IEEE Internet of Things Journal | 2024 | Solves the challenge of simultaneous multi-user authentication by using a dynamically rotating radar to isolate and identify the unique, fine-grained breathing patterns of different individuals from blended RF signals. |

## üå± Agriculture Areas

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [See-Through Soil: Underground Root Tuber Sensing With RF Sensor Networks](https://ieeexplore.ieee.org/abstract/document/11192548) | [Code](https://github.com/Data-driven-RTI/MC_Diffusion) | IEEE Transactions on Geoscience and Remote Sensing  | 2025 | Proposes a deep learning framework (MC-Diffusion) that uses latent diffusion models and domain adaptation techniques to reconstruct fine-grained, cross-sectional images of root tubers from RF sensor network data. |
| [SPYCE: A Multi-Modal Rodent Monitoring Device for Enhanced Detection, Monitoring, and Behavior Analysis](https://ui.adsabs.harvard.edu/abs/2025EGUGA..2713702P/abstract) | [Code](https://github.com/superworld-cyens/MED4PEST) | EGUGA | 2025 | Proposes an open-source, T-shaped multi-modal device (SPYCE) that integrates PIR, ultrasonic, camera, and radar sensors, using flexible activation logic to collect data for training deep-learning-based rodent behavior analysis models. |
| [Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments](https://arxiv.org/abs/2509.02283) | N/A | arXiv | 2025 | Tackles radar perception in cluttered agricultural scenes by using a hierarchical diffusion model that first filters sidelobe artifacts and then generates a fine-grained 3D semantic point cloud, enabling the accurate reconstruction of thin structures. |
| [Hydra: Accurate Multi-Modal Leaf Wetness Sensing with mm-Wave and Camera Fusion](https://dl.acm.org/doi/10.1145/3636534.3690662) | [Code](https://github.com/liuyime2/MobiCom24-Hydra) | ACM MobiCom | 2024 | Achieves accurate leaf wetness sensing for precision agriculture by fusing mm-wave radar's dielectric sensing with camera's visual information. |


## üè≠ Industrial Areas

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [CRFusion: Fine-Grained Object Identification Using RF-Image Modality Fusion](https://ieeexplore.ieee.org/document/10835118) | N/A | IEEE Transactions on Mobile Computing | 2025 | Enables fine-grained object identification in industrial settings by fusing RF material signatures with visual appearance for enhanced discrimination. |

## üîí Forensics & Privacy Security

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| - | - | - | - | - |
| [Attacking mmWave Imaging With Neural Meta-Material Rendering](https://ieeexplore.ieee.org/document/11007126) | N/A | IEEE Transactions on Information Forensics and Security | 2025 | Demonstrates vulnerabilities in mmWave imaging systems by using neural meta-materials to create adversarial patterns that deceive radar-based detection. |
| [mmHSE: Enhanced Eavesdropping Attack on Headsets Leveraging COTS mmWave Radar](https://dl.acm.org/doi/abs/10.1145/3729475) | N/A | Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies | 2025 | Enhances a radar-based eavesdropping attack on headsets by combining a high-resolution beamformer (MVDR+CZT) for precise vibration capture, a spatiotemporal fitting method for signal isolation, and a GAN for audio refinement. |
| [SPACE: Speaker Adaptation for Acoustic Eavesdropping using mmWave Radio Signals](https://ieeexplore.ieee.org/abstract/document/11123722) | N/A | IEEE Transactions on Mobile Computing | 2025 | Tackles the challenge of speaker variability in mmWave eavesdropping by using a speaker encoder to extract and adapt to individual speaker characteristics, enabling more accurate speech reconstruction. |
| [Acoustic Eavesdropping From Sound-Induced Vibrations With Multi-Antenna mmWave Radar](https://ieeexplore.ieee.org/abstract/document/10925836) | N/A | IEEE Transactions on Mobile Computing | 2025 | Overcomes the need for prior training data in acoustic eavesdropping by using multi-antenna signal processing to achieve micrometer-level vibration extraction for speech recovery. |


## üì¶ Other Areas

| Title | Code | Publication | Date | Summary |
| :--- | :---: | :---: | :---: | :--- |
| [We Can Hear You with mmWave Radar! An End-to-End Eavesdropping System](https://arxiv.org/pdf/2511.06205) | N/A | arXiv | 2025 | Achieves through-wall speech eavesdropping by using a mmWave radar to capture loudspeaker-induced vibrations and a deep neural network to reconstruct intelligible speech from the resulting noisy spectrograms. |
| [Multimodal-Wireless: A Large-Scale Dataset for Sensing and Communication](https://arxiv.org/abs/2511.03220) | [Dataset](https://le-liang.github.io/mmw) | arXiv | 2025 | Addresses the lack of datasets for joint sensing and communication research by releasing a large-scale, simulated dataset (Multimodal-Wireless) that uses a CARLA/Sionna pipeline to generate communication channel data synchronized with standard sensor modalities.|
| [RASE 2026: Radar Acoustic Speech Enhancement](https://rase-challenge.github.io/RASE2026-Challenge/) | [Baseline](https://github.com/RASE-Challenge/challenge_baseline2026) | ICASSP 2026 Grand Challenge | 2025 | Enhancement of Speech Signals Acquired Through Glass Using mmWave Radar |
| [Micro-Doppler Classification of Humans and Animals Using FMCW Radar](https://ieeexplore.ieee.org/abstract/document/11205061) | [Code](https://github.com/AmishaManga/MSc-Micro-Doppler-Classification) | IEEE Radar Conference | 2025 | Uses FMCW radar micro-Doppler spectrograms with a two-stage SVM classifier to first differentiate humans from animals and then identify specific animal species for anti-poaching. |
| [A Comprehensive Radar-Based Berthing-Aid Dataset (R-BAD) and Onboard System for Safe Vessel Docking](https://www.mdpi.com/2079-9292/14/20/4065#B12-electronics-14-04065) | [Dataset](https://zenodo.org/records/16936465) [Code](https://github.com/Radar-Uniwa/FMCW-Radar-Based-Berthing-System) | Electronics | 2025 | Addresses the lack of public data for autonomous ship berthing by introducing a large-scale radar and video dataset (R-BAD) and a corresponding onboard system to enable the development of all-weather docking solutions. |
| [How to Talk to Your Classifier: Conditional Text Generation with Radar‚ÄìVisual Latent Space](https://www.mdpi.com/1424-8220/25/14/4467) | N/A | Sensors | 2025 | Addresses the interpretability of radar classifiers by training a model to simultaneously classify an image and generate descriptive text from its latent space, using the text to reveal how the classifier interprets the visual data. |
| [Radar Can See and Hear as Well: A New Multimodal Benchmark Based on Radar Sensing](https://ieeexplore.ieee.org/abstract/document/10517950) | [Code](https://github.com/SPIresearch/RACER) | IEEE Internet of Things Journal | 2024 | Introduces the RACER dataset, a multimodal benchmark with synchronized radar, audio, and visual data, to evaluate radar's ability to sense speech by detecting vocal cord and lip movements. |
| [Wavoice: An mmWave-Assisted Noise-Resistant Speech Recognition System](https://dl.acm.org/doi/full/10.1145/3597457) | [Code](https://github.com/TitaniumLiu/Wavoice) | ACM Transactions on Sensor Networks| 2024 | Enhances speech recognition in noisy environments by using mmWave radar to capture lip and vocal cord movements, fusing this data with audio inputs for improved accuracy. |
| [Seeing the Invisible: Recovering Surveillance Video With COTS mmWave Radar](https://ieeexplore.ieee.org/abstract/document/10638821) | N/A | IEEE Transactions on Mobile Computing | 2024 | Solves the problem of camera failure/obscuration by using a generative network to fuse real-time mmWave motion data with pre-acquired visual appearance data to reconstruct the video. |
| [UFace: Your Smartphone Can "Hear" Your Facial Expression!](https://dl.acm.org/doi/abs/10.1145/3643546) | [Code](https://github.com/Sulingy/UFace) | Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies | 2024 | Solves the challenge of unobtrusive facial expression recognition by using a smartphone's acoustic signals (not camera/radar) with a dual-stream attention network to extract fine-grained motion-related changes.|
| [Introducing an indoor object classification dataset including sparse point clouds from mmWave radar](https://www.nature.com/articles/s41597-024-03678-2) | [Code](https://github.com/ounospanas/RadIOCD) | Scientific Data | 2024 | Fills the gap in public datasets for indoor object classification by releasing RadIOCD, which contains synchronized sparse mmWave radar point clouds and RGB-D images of common household items. |
| [SuperSight: Sub-cm NLOS Localization for mmWave Backscatter](https://dl.acm.org/doi/abs/10.1145/3643832.3661857) | [Code](https://github.com/smilelabkaist/SuperSight) | ACM International Conference on Mobile Systems, Applications, and Services (MobiSys) | 2024 | Achieves sub-cm non-line-of-sight (NLOS) localization by using a triangular retro-reflective tag array to uniquely exploit directional mmWave multipath, eliminating the need for environmental profiling. |

## ü§ù How to Contribute

Contributions are always welcome! This list is actively maintained.

Please read the [**contribution guidelines**](CONTRIBUTING.md) before submitting your pull request.

## License

[![CC0](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)